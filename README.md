# A Hybrid Fusion Framework for Anomaly Detection in IoMT

This repository contains the official code and experiments for the research paper. The project proposes and validates a hybrid fusion framework for detecting and distinguishing between security, physiological, and technical anomalies in Internet of Medical Things (IoMT) environments.

## 🎯 Project Goal

Modern healthcare relies heavily on wearable IoT devices (e.g., heart rate, BP, oxygen levels). Sensor faults, data drift, or malicious interference can compromise monitoring reliability. This research proposes a multi-sensor fusion framework to detect anomalies in physiological signals—even under device malfunction or uncertainty—ensuring patient safety.

---

---
## 🌳 Repository Branches

This repository has two primary branches for different purposes:

* **`main`**: This is the lightweight, code-only branch. It's designed for users who want to run the entire pipeline from scratch to ensure full reproducibility. You will need to download the raw datasets and run all notebooks in order as described below.

* **`release`**: This branch includes all the pre-computed processed data (`.parquet`, `.npy`) and the final trained models (`.joblib`, `.keras`). This is ideal for users who want to quickly run the final fusion and evaluation notebook (`03_fusion_framework_evaluation.ipynb`) without the time-consuming preprocessing and training steps. **Note:** This branch requires Git LFS to be installed.
---


## 📂 Repository Structure (Release branch with all files)

The repository is organized as follows:

```
.
├── data/
│   ├── raw/         # Directory for raw datasets (must be downloaded manually)
│   └── processed/   # Intermediate, processed data files generated by the notebooks
├── notebooks/
│   ├── 01_security_module.ipynb
│   ├── 02_physiological_module.ipynb
│   └── 03_fusion_framework_evaluation.ipynb
├── models/          # Saved, trained machine learning models
├── .gitignore
├── requirements.txt # All Python dependencies
└── README.md        # This file
```

---


## 🛠️ Setup and Installation

To replicate the experiments, please follow these steps:

### 1. Clone the Repository
```bash
git clone [https://github.com/syriuslab/fusion_framework.git](https://github.com/syriuslab/fusion_framework.git)
cd fusion_framework
```

### 2. Install Dependencies
This project uses Python 3.11. All required libraries are listed in the `requirements.txt` file. Install them using pip:
```bash
pip install -r requirements.txt
```

### 3. Download Datasets
The datasets used in this study are publicly available but are too large to be included in this repository.

* **CICIOMT2024:** Download the dataset from [**http://cicresearch.ca/IOTDataset/CICIoMT2024/**]. Unzip and place all the training `.csv` files inside the following directory:
    `./data/raw/ciciomt2024/`

* **MIMIC-IV Demo:** Download the dataset from [**https://physionet.org/content/mimic-iv-demo/get-zip/2.2/**]. Place the relevant files in a new directory:
    `./data/raw/mimic-iv-demo/`

---
# 🚀 Running the Experiments

The experiments are divided into three notebooks that must be run in order.

### **⚠️ Important: Modify File Paths in Each Notebook**

Each notebook contains **absolute paths** from its original Google Colab environment. Before running, you **must update these paths** to be relative to this project's structure. Anyway, if your are using Google Colab environment, you have just to copy paste files and use the same path.

#### 4.1 - Run `01_security_module.ipynb`
This notebook processes the CICIOMT2024 dataset and trains the XGBoost model.
1.  Open `notebooks/01_security_module.ipynb`.
2.  **Update all paths** for loading raw data and saving the model and processed data.
3.  Run all cells. This will generate the following key files:
    * `models/xgboost_security_model.joblib`
    * `data/processed/security_X_test.npy`
    * `data/processed/security_y_test.npy`

#### 4.2 - Run `02_physiological_module.ipynb`
This notebook processes the MIMIC-IV Demo dataset and trains the LSTM Autoencoder.
1.  Open `notebooks/02_physiological_module.ipynb`.
2.  **Update all paths** for loading raw data and saving the model and processed data.
3.  Run all cells. This will generate the following key files:
    * `models/lstm_autoencoder_physiological.keras`
    * `data/processed/physiological_X_test_sequences.npy`

#### 4.3 - Run `03_fusion_framework_evaluation.ipynb`
This notebook loads the trained models and test data from the previous steps to run the fusion logic and produce the final results.
1.  Open `notebooks/03_fusion_framework_evaluation.ipynb`.
2.  **Update the paths** at the beginning to **load** the assets generated in the previous steps.
3.  Run all cells to perform the final fusion, evaluation, and generate all tables and figures for the paper.

---
---


## ©️ Citation

If you use this code or our findings in your research, please cite our paper, hope to be published soon :) 
