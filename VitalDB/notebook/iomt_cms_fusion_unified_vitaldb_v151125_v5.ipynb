{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be600cc",
   "metadata": {
    "id": "9be600cc"
   },
   "source": [
    "# IoMT Cyber-Medical Fusion Framework\n",
    "\n",
    "Unified notebook combining:\n",
    "1. Security module (CICIoMT2024)\n",
    "2. Physiological module (VitalDB, replacing MIMIC-IV Demo)\n",
    "3. Fusion and evaluation framework.\n",
    "\n",
    "All original comments are preserved; only the physiological data-loading step was refactored to use VitalDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6eeba9",
   "metadata": {
    "id": "8e6eeba9"
   },
   "source": [
    "## 1. Security Module (original notebook `01_security_module.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed969929",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed969929",
    "outputId": "effdc214-1710-4cac-d584-6aa1ba502185"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 0: ENVIRONMENT SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Mount Google Drive ---\n",
    "# This command connects your Colab notebook to your Google Drive.\n",
    "# You will be prompted to authorize the connection.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted successfully!\")\n",
    "\n",
    "# --- 2. Install necessary libraries (if not already installed) ---\n",
    "!pip install xgboost shap -q\n",
    "\n",
    "print(\"Setup complete. You can now proceed with Step 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdeda50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8cdeda50",
    "outputId": "08ba6ff2-69e8-48ab-9628-b471facb2520"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 1: LOAD, MERGE, AND OPTIMIZE A MULTI-FILE DATASET\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import gc # Garbage Collector interface\n",
    "\n",
    "# --- Helper function to reduce memory usage ---\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Iterates through all the columns of a dataframe and modifies the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print(f'Mem. usage decreased to {end_mem:5.2f} Mb ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
    "    return df\n",
    "\n",
    "# --- 1. Define the exact path to your training data folder ---\n",
    "train_folder_path = '/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/train_data_CICIoMT2024/train'\n",
    "\n",
    "# --- 2. Get a list of all CSV files in the folder ---\n",
    "print(f\"Searching for CSV files in: {train_folder_path}\")\n",
    "all_csv_files = glob.glob(os.path.join(train_folder_path, \"*.csv\"))\n",
    "\n",
    "if not all_csv_files:\n",
    "    print(f\"ERROR: No CSV files found in the specified directory.\")\n",
    "    print(\"Please check that the path is correct and the files have been uploaded.\")\n",
    "else:\n",
    "    print(f\"Found {len(all_csv_files)} CSV files to merge.\")\n",
    "\n",
    "    # --- 3. Loop through the files, read them, and add the 'label' column ---\n",
    "    list_of_dataframes = []\n",
    "    for f in all_csv_files:\n",
    "        try:\n",
    "            temp_df = pd.read_csv(f)\n",
    "            file_name = os.path.basename(f)\n",
    "            label_name = file_name.split('_train.pcap.csv')[0]\n",
    "            if 'Benign' in label_name:\n",
    "                label_name = 'Normal'\n",
    "            temp_df['label'] = label_name\n",
    "            list_of_dataframes.append(temp_df)\n",
    "            print(f\"Processed {file_name} -> assigned label '{label_name}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {f}: {e}\")\n",
    "\n",
    "    # --- 4. Concatenate, clean up, and optimize ---\n",
    "    if list_of_dataframes:\n",
    "        print(\"\\nMerging all dataframes...\")\n",
    "        df = pd.concat(list_of_dataframes, ignore_index=True)\n",
    "        print(\"Merge complete!\")\n",
    "\n",
    "        # Clean up intermediate list to free up RAM\n",
    "        del list_of_dataframes\n",
    "        gc.collect()\n",
    "        print(\"Intermediate memory freed.\")\n",
    "\n",
    "        # === APPLY MEMORY OPTIMIZATION ===\n",
    "        print(\"\\nOptimizing memory usage of the final dataframe...\")\n",
    "        df = reduce_mem_usage(df)\n",
    "\n",
    "        # --- 5. Final check and shuffle ---\n",
    "        print(\"\\n--- Info on the final, optimized dataframe ---\")\n",
    "        display(df.info(memory_usage='deep'))\n",
    "\n",
    "        print(\"\\n--- Class distribution in the final dataframe ---\")\n",
    "        display(df['label'].value_counts())\n",
    "\n",
    "        # Shuffle the dataframe\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        print(\"\\nFinal dataframe has been shuffled.\")\n",
    "\n",
    "        print(\"\\n--- First 5 rows of the final dataframe ---\")\n",
    "        display(df.head())\n",
    "    else:\n",
    "        print(\"No dataframes were loaded. Please check the source files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649079f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0649079f",
    "outputId": "33917da3-c328-45ea-8417-1666b06d3f0d"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SAVE THE MERGED SECURITY DATAFRAME\n",
    "# Run this cell in your security notebook after the data has been loaded and merged\n",
    "# ==============================================================================\n",
    "\n",
    "# Ensure the final merged dataframe 'df' exists\n",
    "if 'df' in locals():\n",
    "    # Define the path where the file will be saved\n",
    "    save_path = '/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/merged_ciciomt_data.parquet'\n",
    "\n",
    "    # Save the dataframe to a Parquet file\n",
    "    print(f\"Saving the merged security dataframe to {save_path}...\")\n",
    "    df.to_parquet(save_path)\n",
    "    print(\"Save complete!\")\n",
    "else:\n",
    "    print(\"ERROR: Dataframe 'df' not found. Please run the data loading and merging step first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d64283",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14d64283",
    "outputId": "93938d71-892b-48b2-99fb-0f3cff7a38e9"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 2-A (MODIFIED FOR BINARY TEST): PREPROCESSING JUST FOR FEATURE VALIDATING\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "if 'df' in locals():\n",
    "    print(\"Starting data preprocessing for BINARY classification...\")\n",
    "\n",
    "    # --- Pulizia e encoding iniziale (rimane uguale) ---\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(df.select_dtypes(include=np.number).mean(), inplace=True)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    # --- Separazione Feature/Target e rimozione colonne (rimane uguale) ---\n",
    "    X = df.select_dtypes(include=np.number).drop(['label_encoded'], axis=1)\n",
    "    cols_to_drop = [\n",
    "        'Protocol Type', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC',\n",
    "        'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IGMP', 'IPv', 'LLC'\n",
    "    ]\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop if col in X.columns]\n",
    "    if existing_cols_to_drop:\n",
    "        X = X.drop(columns=existing_cols_to_drop)\n",
    "\n",
    "\n",
    "    #/!\\ BINARY MODE: We create a binary target: 0 -> 'Normal', 1 -> 'Attack'\n",
    "    normal_label_code = label_mapping['Normal']\n",
    "    y_binary = np.where(df['label_encoded'] == normal_label_code, 0, 1)\n",
    "    y = y_binary # Usiamo il nuovo target binario\n",
    "    print(f\"-> Created a new BINARY target: 0 = Normal, 1 = Attack\")\n",
    "\n",
    "    # --- Scaling ---\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    print(\"-> Data prepared for binary classification.\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Dataframe 'df' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeafc30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "dfeafc30",
    "outputId": "1cc8ed46-6aa1-460d-fe1b-8dcd310a3cdc"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 2-B: PREPROCESSING FOR GROUPED CLASSES\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We make sure that 'df' and 'X' still exist\n",
    "if 'df' in locals() and 'X' in locals():\n",
    "    print(\"Starting preprocessing for GROUPED classification...\")\n",
    "\n",
    "    # --- 1. Grouping all attack types ---\n",
    "    def group_attack_labels(label):\n",
    "        if 'Normal' in label:\n",
    "            return 'Normal'\n",
    "        if 'DDoS' in label:\n",
    "            return 'DDoS'\n",
    "        if 'DoS' in label:\n",
    "            return 'DoS'\n",
    "        if 'Recon' in label:\n",
    "            return 'Recon'\n",
    "        if 'ARP_Spoofing' in label:\n",
    "            return 'Spoofing'\n",
    "        if 'Malformed' in label:\n",
    "            return 'Malformed'\n",
    "        return 'Other'  # Fallback category, if needed\n",
    "\n",
    "    # --- 2. Creating the new column with grouped labels ---\n",
    "    df['grouped_label'] = df['label'].apply(group_attack_labels)\n",
    "    print(\"-> Created a new 'grouped_label' column.\")\n",
    "    print(\"\\n--- Distribution of the new grouped classes ---\")\n",
    "    display(df['grouped_label'].value_counts())\n",
    "\n",
    "    # --- 3. Encoding the new grouped labels ---\n",
    "    grouped_label_encoder = LabelEncoder()\n",
    "    y_grouped = grouped_label_encoder.fit_transform(df['grouped_label'])\n",
    "\n",
    "    # --- 4. Splitting into Training and Test sets ---\n",
    "    # We reuse the same scaled features 'X_scaled' from binary classification\n",
    "    X_train_grouped, X_test_grouped, y_train_grouped, y_test_grouped = train_test_split(\n",
    "        X_scaled, y_grouped, test_size=0.3, random_state=42, stratify=y_grouped\n",
    "    )\n",
    "    print(\"\\n-> Data split for grouped classification complete.\")\n",
    "    print(f\"   Training set: {X_train_grouped.shape[0]} samples\")\n",
    "    print(f\"   Test set: {X_test_grouped.shape[0]} samples\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Make sure you have successfully executed the previous steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97fac0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6d97fac0",
    "outputId": "97092611-46c2-481b-a201-d29cfbd08fe5"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 3-A (UPDATED WITH AUC-ROC): XGBOOST FOR BINARY CLASSIFICATION\n",
    "# ==============================================================================\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if training data exists\n",
    "if 'X_train' in locals() and 'y_binary' in locals():\n",
    "    print(\"--- Training XGBoost Model for BINARY Classification ---\")\n",
    "\n",
    "    # Initialize the XGBoost classifier for binary classification\n",
    "    xgb_model_binary = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        device='cuda'  # Use GPU if available\n",
    "    )\n",
    "\n",
    "    print(\"Starting training on GPU...\")\n",
    "    xgb_model_binary.fit(X_train, y_train)  # Make sure y_train is the binary label set\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- Evaluation on the Test Set ---\n",
    "    print(\"\\n--- Evaluating on Test Set ---\")\n",
    "    y_pred_binary = xgb_model_binary.predict(X_test)\n",
    "    y_pred_proba_binary = xgb_model_binary.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    print(f\"Overall Accuracy: {accuracy_score(y_test, y_pred_binary) * 100:.2f}%\")\n",
    "\n",
    "    # --- AUC-ROC Calculation ---\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_binary)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"AUC-ROC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    print(\"\\nDetailed Classification Report (Normal vs Attack):\")\n",
    "    print(classification_report(y_test, y_pred_binary, target_names=['Normal', 'Attack']))\n",
    "\n",
    "    # --- Plotting ROC Curve ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line (random guess)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Training data not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a043b93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8a043b93",
    "outputId": "80859110-e3f6-47d1-eb9c-22558ec5691c"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 3-B (UPDATED WITH AUC-ROC): XGBOOST FOR GROUPED CLASSES\n",
    "# ==============================================================================\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "# Ensure the grouped training/test data exists\n",
    "if 'X_train_grouped' in locals() and 'y_test_grouped' in locals():\n",
    "    print(\"--- Training and Evaluating XGBoost Model ---\")\n",
    "\n",
    "    # Model definition\n",
    "    xgb_model_grouped = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        device='cuda'\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    xgb_model_grouped.fit(X_train_grouped, y_train_grouped)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    y_pred_grouped = xgb_model_grouped.predict(X_test_grouped)\n",
    "    y_pred_proba_grouped = xgb_model_grouped.predict_proba(X_test_grouped)\n",
    "\n",
    "    # Calculate the single, robust metric we want to display\n",
    "    roc_auc_macro = roc_auc_score(y_test_grouped, y_pred_proba_grouped, multi_class='ovr', average='macro')\n",
    "\n",
    "    print(f\"\\nOverall Accuracy: {accuracy_score(y_test_grouped, y_pred_grouped):.6f}\")\n",
    "    print(f\"Macro-Average AUC-ROC Score: {roc_auc_macro:.6f}\") # This is our key score\n",
    "\n",
    "    print(\"\\nDetailed Classification Report (6 Classes, High Precision):\")\n",
    "    print(classification_report(y_test_grouped, y_pred_grouped, target_names=grouped_label_encoder.classes_, digits=4))\n",
    "\n",
    "    # --- Plotting ROC Curve with a single, aggregated score in the title ---\n",
    "    y_test_binarized = label_binarize(y_test_grouped, classes=range(len(grouped_label_encoder.classes_)))\n",
    "    n_classes = y_test_binarized.shape[1]\n",
    "    fpr, tpr = dict(), dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_proba_grouped[:, i])\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        # The label now only contains the class name for a cleaner legend\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of class {grouped_label_encoder.classes_[i]}')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n",
    "\n",
    "    # === KEY CHANGE: The main result is now in the title ===\n",
    "    plt.title(f'XGBoost - Multi-Class ROC Curve\\n(Macro-Average AUC = {roc_auc_macro:.6f})', fontsize=16)\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Grouped training/test data not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae41024",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7ae41024",
    "outputId": "61fbbb68-2d1a-46cd-c9fe-3bdc43b6ef1d"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 4: VISUALIZING MODEL PERFORMANCE AND INTERPRETABILITY\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "# Ensure that the necessary model and data variables exist\n",
    "if 'xgb_model_grouped' in locals() and 'X_test_grouped' in locals():\n",
    "\n",
    "    # --- PLOT 1: CONFUSION MATRIX ---\n",
    "    # This plot shows in detail where the model performs well and where it makes mistakes.\n",
    "    print(\"--- Generating Confusion Matrix ---\")\n",
    "\n",
    "    cm = confusion_matrix(y_test_grouped, y_pred_grouped)\n",
    "    class_names = grouped_label_encoder.classes_\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix for Grouped Classes', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 2: FEATURE IMPORTANCE ---\n",
    "    # This plot shows which features the model considered most important for making its decisions.\n",
    "    print(\"\\n--- Generating Feature Importance Plot ---\")\n",
    "\n",
    "    feature_importances = xgb_model_grouped.feature_importances_\n",
    "    # Create a DataFrame for easier plotting\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns, # Using column names from 'X' before scaling\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Display the top 20 most important features\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Most Important Features (XGBoost)', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.grid(axis='x')\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 3: SHAP SUMMARY PLOT ---\n",
    "    # This is the most advanced plot: it shows not only WHICH features are important,\n",
    "    # but also HOW their values impact the prediction for each class.\n",
    "    print(\"\\n--- Generating SHAP Summary Plot (this may take a moment) ---\")\n",
    "\n",
    "    # Use a subset of the test set to speed up SHAP calculations\n",
    "    X_test_sample_shap = pd.DataFrame(X_test_grouped[:2000], columns=X.columns)\n",
    "\n",
    "    explainer = shap.TreeExplainer(xgb_model_grouped)\n",
    "    shap_values = explainer.shap_values(X_test_sample_shap)\n",
    "\n",
    "    # Plot the SHAP summary\n",
    "    shap.summary_plot(shap_values, X_test_sample_shap,\n",
    "                      class_names=class_names,\n",
    "                      show=False)\n",
    "    plt.title(\"SHAP Summary Plot - Feature Impact on Model Output\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Make sure Step 3-B has been run successfully to generate the model and results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e016c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63e016c0",
    "outputId": "f670f9b1-b8e2-4c92-a8f0-5aa6f66d892f"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 5: CROSS-VALIDATION FOR XGBOOST MODEL (SEQUENTIAL EXECUTION)\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# Make sure the required data exists\n",
    "if 'X_scaled' in locals() and 'y_grouped' in locals():\n",
    "    print(\"--- Starting 5-Fold Cross-Validation (Sequential Mode) ---\")\n",
    "    print(\"This process will be slower but more memory-efficient.\")\n",
    "\n",
    "    # Define the model again to ensure it's a fresh instance\n",
    "    xgb_model_for_cv = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',        # Multiclass classification\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        tree_method='hist',                # Histogram-based (faster on large datasets)\n",
    "        device='cuda'                      # Use GPU if available\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation sequentially\n",
    "    # 'n_jobs=-1' was removed to avoid memory crashes\n",
    "    scores = cross_val_score(\n",
    "        estimator=xgb_model_for_cv,\n",
    "        X=X_scaled,\n",
    "        y=y_grouped,\n",
    "        cv=5,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "\n",
    "    print(\"\\nCross-Validation complete.\")\n",
    "    print(f\"Scores for each of the {len(scores)} folds: {scores}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(scores) * 100:.2f}%\")\n",
    "    print(f\"Standard Deviation: {np.std(scores) * 100:.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Data for cross-validation not found. Please run the previous steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ae7a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b58ae7a8",
    "outputId": "d07466cb-7a6b-4a1f-8593-9f59540e75e8"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FINAL STEP: INTERPRETABILITY WITH SHAP\n",
    "# ==============================================================================\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure SHAP values have already been computed\n",
    "if 'shap_values' in locals() and 'X_test_sample_shap' in locals():\n",
    "    print(\"--- Generating Individual SHAP Plots for Each Class (Corrected Slicing) ---\")\n",
    "\n",
    "    # Initialize SHAP visualization\n",
    "    shap.initjs()\n",
    "\n",
    "    # Retrieve class names from our label encoder\n",
    "    class_names = grouped_label_encoder.classes_\n",
    "\n",
    "    # === LOOP TO GENERATE A SEPARATE PANEL FOR EACH CLASS ===\n",
    "    for i, class_name in enumerate(class_names):\n",
    "\n",
    "        print(f\"\\n--- SHAP Summary Plot for Class: '{class_name}' ---\")\n",
    "\n",
    "\n",
    "        # Select SHAP values for the i-th class using correct slicing for a 3D array\n",
    "        shap.summary_plot(\n",
    "            shap_values[:, :, i],  # Select ALL samples, ALL features, for class i\n",
    "            X_test_sample_shap,\n",
    "            show=True\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Make sure SHAP values were computed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c2fbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "498c2fbc",
    "outputId": "f51a80f5-68dc-4c1a-9f3b-d26ed60ad6fa"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 6: ISOLATION FOREST WITH VALID PARAMETERS AND AUC-ROC (First TEST, NOT SO GOOD!!)\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure training data is available\n",
    "if 'X_train' in locals() and 'y_train' in locals():\n",
    "    print(\"--- Training Isolation Forest Model (Unsupervised) ---\")\n",
    "\n",
    "    # The binary target is: 0 = Normal, 1 = Attack\n",
    "    y_binary_train = np.where(y_train == 0, 0, 1)  # Ensure binary target for training\n",
    "    X_train_normal_iso = X_train[y_binary_train == 0]  # Use only \"Normal\" samples for training\n",
    "    print(f\"Training will be performed on {X_train_normal_iso.shape[0]} 'Normal' samples.\")\n",
    "\n",
    "    # Define and train the model\n",
    "    # === FIX: 'contamination' must be <= 0.5. Use 'auto' to let the model decide ===\n",
    "    iso_forest = IsolationForest(\n",
    "        n_estimators=100,\n",
    "        contamination='auto',  # Let the model determine the contamination threshold\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    iso_forest.fit(X_train_normal_iso)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- Evaluation on the Test Set ---\n",
    "    # Get the anomaly decision scores\n",
    "    decision_scores = iso_forest.decision_function(X_test)\n",
    "    y_pred_proba_iso = -decision_scores  # Higher score means more likely to be an anomaly\n",
    "\n",
    "    # Get binary predictions\n",
    "    y_pred_iso_raw = iso_forest.predict(X_test)\n",
    "    y_pred_iso = np.where(y_pred_iso_raw == 1, 0, 1)  # 1 → Normal (0), -1 → Anomaly (1)\n",
    "\n",
    "    y_test_binary_iso = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "    print(\"\\n--- Evaluating on Test Set (Normal vs. Attack) ---\")\n",
    "    print(f\"Overall Accuracy: {accuracy_score(y_test_binary_iso, y_pred_iso) * 100:.2f}%\")\n",
    "\n",
    "    # --- AUC-ROC Calculation ---\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary_iso, y_pred_proba_iso)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"AUC-ROC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    print(\"\\nDetailed Classification Report (Normal vs Attack):\")\n",
    "    print(classification_report(y_test_binary_iso, y_pred_iso, target_names=['Normal', 'Attack']))\n",
    "\n",
    "    # --- Plotting ROC Curve ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal reference line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Isolation Forest - ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Binary data not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48997c81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "id": "48997c81",
    "outputId": "189e2e7d-ef27-4b96-bbb4-9a92f993272f"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FINAL STEP: COMPLETE EVALUATION OF ISOLATION FOREST\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, precision_recall_curve, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure the necessary data is available\n",
    "if 'X_train' in locals() and 'y_train' in locals():\n",
    "    print(\"--- Training Isolation Forest Model (Unsupervised) ---\")\n",
    "\n",
    "    # Create binary labels: 0 = Normal, 1 = Attack\n",
    "    y_binary_train = np.where(y_train == 0, 0, 1)\n",
    "    X_train_normal_iso = X_train[y_binary_train == 0]\n",
    "\n",
    "    # Define and train the model\n",
    "    iso_forest = IsolationForest(\n",
    "        n_estimators=100,\n",
    "        contamination='auto',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    iso_forest.fit(X_train_normal_iso)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- Compute scores and prepare test data ---\n",
    "    decision_scores = iso_forest.decision_function(X_test)\n",
    "    y_pred_proba_iso = -decision_scores  # Higher score = more anomalous\n",
    "    y_test_binary = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "    # --- 1. Compute and Plot the AUC-ROC Curve ---\n",
    "    print(\"\\n--- Evaluating Model's Separation Capability ---\")\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary, y_pred_proba_iso)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"AUC-ROC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Isolation Forest - ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # --- 2. Optimize the Decision Threshold based on F1-Score ---\n",
    "    print(\"\\n--- Optimizing Decision Threshold based on F1-Score ---\")\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_binary, y_pred_proba_iso)\n",
    "    f1_scores = (2 * recalls * precisions) / (recalls + precisions + 1e-9)\n",
    "    best_f1_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[best_f1_idx]\n",
    "    optimal_decision_threshold = -optimal_threshold  # Invert since we negated earlier\n",
    "\n",
    "    print(f\"Optimal threshold found: {optimal_decision_threshold:.4f}\")\n",
    "\n",
    "    # --- 3. Final Evaluation using the Optimized Threshold ---\n",
    "    y_pred_optimal = np.where(decision_scores < optimal_decision_threshold, 1, 0)\n",
    "\n",
    "    print(\"\\n--- Final Evaluation with Optimal Threshold ---\")\n",
    "    print(f\"Overall Accuracy: {accuracy_score(y_test_binary, y_pred_optimal) * 100:.2f}%\")\n",
    "    print(\"\\nDetailed Classification Report (Optimized):\")\n",
    "    print(classification_report(y_test_binary, y_pred_optimal, target_names=['Normal', 'Attack']))\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Binary data not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad42362",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9ad42362",
    "outputId": "9287a2ef-1b59-4a42-f7af-76e9b837c1f8"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 7: INTERPRETABILITY FOR ISOLATION FOREST (FINAL & SELF-CONTAINED)\n",
    "# ==============================================================================\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check that the required variables exist\n",
    "if 'iso_forest' in locals() and 'X_test' in locals():\n",
    "    print(\"--- Generating SHAP Plot for Isolation Forest ---\")\n",
    "    print(\"This process will analyze what the model considers anomalous.\")\n",
    "\n",
    "    # --- SAFETY BLOCK FOR FEATURE NAMES ---\n",
    "    # Define correct feature names here to make the cell self-contained\n",
    "    X_for_names = df.select_dtypes(include=np.number).drop(['label_encoded', 'label'], axis=1, errors='ignore')\n",
    "\n",
    "    cols_to_drop = [\n",
    "        'Protocol Type', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC',\n",
    "        'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IGMP', 'IPv', 'LLC'\n",
    "    ]\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop if col in X_for_names.columns]\n",
    "\n",
    "    if existing_cols_to_drop:\n",
    "        X_for_names = X_for_names.drop(columns=existing_cols_to_drop)\n",
    "\n",
    "    correct_feature_names = X_for_names.columns\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # Prepare a sample of test data with the correct column names\n",
    "    X_test_sample_shap_iso = pd.DataFrame(X_test[:2000], columns=correct_feature_names)\n",
    "\n",
    "    # Initialize SHAP plotting (important in Colab or notebooks)\n",
    "    shap.initjs()\n",
    "\n",
    "    # Create a SHAP explainer and compute SHAP values\n",
    "    iso_explainer = shap.TreeExplainer(iso_forest)\n",
    "    iso_shap_values = iso_explainer.shap_values(X_test_sample_shap_iso)\n",
    "    print(\"SHAP values calculated successfully.\")\n",
    "\n",
    "    # Generate the summary plot\n",
    "    print(\"\\n--- Generating SHAP Summary Plot ---\")\n",
    "    shap.summary_plot(iso_shap_values, X_test_sample_shap_iso)\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Make sure the required variables ('iso_forest', 'X_test', 'df') exist by running the previous steps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03f5e",
   "metadata": {
    "id": "7ef03f5e"
   },
   "source": [
    "LSTM - TRAINING AND SEQUENTIAL WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e6164",
   "metadata": {
    "id": "b97e6164"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(X_data, y_data, time_steps=10):\n",
    "    \"\"\"\n",
    "    Create sequential series on 2D data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Time window extraction\n",
    "        v = X_data[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        # Assigning labels on the last window\n",
    "        ys.append(y_data[i + time_steps - 1])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b22e54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d4b22e54",
    "outputId": "501086e9-ddff-4ef6-f30a-c3e1448d1cba"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FINAL & COMPLETE: CNN-LSTM WITH BALANCED CLASSES AND AUC-ROC PLOT\n",
    "# ==============================================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "# --- Helper Functions and Classes ---\n",
    "def create_sequences(X_data, y_data, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        v = X_data[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(y_data[i + time_steps - 1])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "class TimeSeriesGenerator(Sequence):\n",
    "    def __init__(self, X_data, y_data, batch_size, time_steps):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.time_steps = time_steps\n",
    "        self.indices = np.arange(len(X_data) - time_steps)\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = (index + 1) * self.batch_size\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        X_batch, y_batch = [], []\n",
    "        for i in batch_indices:\n",
    "            X_batch.append(self.X_data[i:(i + self.time_steps)])\n",
    "            y_batch.append(self.y_data[i + self.time_steps - 1])\n",
    "        return np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "# --- Training and Evaluation ---\n",
    "if 'X_train_grouped' in locals():\n",
    "    # 1. Calculate Class Weights\n",
    "    print(\"--- Calculating class weights... ---\")\n",
    "    weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_grouped), y=y_train_grouped)\n",
    "    class_weights = dict(enumerate(weights))\n",
    "\n",
    "    # 2. Prepare Generators and Parameters\n",
    "    TIME_STEPS = 20\n",
    "    BATCH_SIZE = 1024\n",
    "    training_generator = TimeSeriesGenerator(X_train_grouped, y_train_grouped, BATCH_SIZE, TIME_STEPS)\n",
    "    test_generator = TimeSeriesGenerator(X_test_grouped, y_test_grouped, BATCH_SIZE, TIME_STEPS)\n",
    "\n",
    "    n_features = X_train_grouped.shape[1]\n",
    "    n_outputs = len(grouped_label_encoder.classes_)\n",
    "\n",
    "    # 3. Build the Model\n",
    "    print(\"\\n--- Building Time-Series CNN-LSTM Model ---\")\n",
    "    cnn_lstm_model_balanced = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(TIME_STEPS, n_features), padding='same'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(n_outputs, activation='softmax')\n",
    "    ])\n",
    "    cnn_lstm_model_balanced.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 4. Train the Model\n",
    "    print(\"\\n--- Training CNN-LSTM Model with Class Weights ---\")\n",
    "    history_balanced = cnn_lstm_model_balanced.fit(training_generator, epochs=5, verbose=1, class_weight=class_weights)\n",
    "\n",
    "    # 5. Complete Evaluation on Test Set\n",
    "    print(\"\\n--- Full Evaluation on Test Set ---\")\n",
    "    y_pred_proba_cnn = cnn_lstm_model_balanced.predict(test_generator)\n",
    "    y_pred_cnn = np.argmax(y_pred_proba_cnn, axis=1)\n",
    "\n",
    "    _, y_test_aligned = create_sequences(X_test_grouped, y_test_grouped, TIME_STEPS)\n",
    "    y_test_final = y_test_aligned[:len(y_pred_cnn)]\n",
    "\n",
    "    roc_auc_macro = roc_auc_score(y_test_final, y_pred_proba_cnn, multi_class='ovr', average='macro')\n",
    "\n",
    "    print(f\"\\nOverall Accuracy: {accuracy_score(y_test_final, y_pred_cnn) * 100:.2f}%\")\n",
    "    print(f\"Macro-Average AUC-ROC Score: {roc_auc_macro:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report (6 Classes):\")\n",
    "    print(classification_report(y_test_final, y_pred_cnn, target_names=grouped_label_encoder.classes_))\n",
    "\n",
    "    # === BLOCCO GRAFICO AUC-ROC (AGGIUNTO) ===\n",
    "    print(\"\\n--- Generating Multi-Class ROC Curve Plot ---\")\n",
    "    y_test_binarized = label_binarize(y_test_final, classes=range(n_outputs))\n",
    "    fpr, tpr, roc_auc_dict = dict(), dict(), dict()\n",
    "\n",
    "    for i in range(n_outputs):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_proba_cnn[:, i])\n",
    "        roc_auc_dict[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for i, color in zip(range(n_outputs), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC of class {grouped_label_encoder.classes_[i]} (area = {roc_auc_dict[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('CNN-LSTM - Multi-Class ROC Curve', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Grouped data not found. Please re-run the necessary preprocessing steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9ec4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8d9ec4a",
    "outputId": "37d6c63e-0c8e-49ef-d0e7-d2421e0af0ad"
   },
   "outputs": [],
   "source": [
    "# Save the trained XGBoost model\n",
    "import joblib\n",
    "joblib.dump(xgb_model_grouped, '/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/xgb_model_grouped.joblib')\n",
    "print(\"XGBoost model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8867d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5d8867d",
    "outputId": "239e049f-219f-4ac3-f7b4-424408cb2f99"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# SAVE SECURITY TEST DATA\n",
    "# Run this cell once after preprocessing is complete\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "\n",
    "# Check if the variables exist before saving\n",
    "if 'X_test_grouped' in locals() and 'y_test_grouped' in locals():\n",
    "    print(\"Saving security test data to files...\")\n",
    "    np.save('/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/X_test_grouped.npy', X_test_grouped)\n",
    "    np.save('/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/y_test_grouped.npy', y_test_grouped)\n",
    "    print(\"✅ Security test data saved successfully.\")\n",
    "else:\n",
    "    print(\"❌ ERROR: 'X_test_grouped' or 'y_test_grouped' not found. Please run the preprocessing cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b818dd",
   "metadata": {
    "id": "a6b818dd"
   },
   "source": [
    "## 2. Physiological Module (patched to use VitalDB instead of MIMIC-IV Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e2639",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e1e2639",
    "outputId": "476aadfa-5986-4ab1-b0f0-dd21c705e44e"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 0: ENVIRONMENT SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Mount Google Drive ---\n",
    "# This command connects your Colab notebook to your Google Drive.\n",
    "# You will be prompted to authorize the connection.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted successfully!\")\n",
    "\n",
    "# --- 2. Install necessary libraries (if not already installed) ---\n",
    "!pip install xgboost shap vitaldb -q\n",
    "\n",
    "print(\"Setup complete. You can now proceed with Step 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3EOmxc9_ovBY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EOmxc9_ovBY",
    "outputId": "9e3dd41e-ef61-4caa-f843-366a8fa8bdf2"
   },
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# T1_fix — Initialization\n",
    "# ==========================\n",
    "import vitaldb\n",
    "\n",
    "# Candidate aliases for each vital. Track names vary across sites/devices,\n",
    "# so we keep broad lists and pick the first available in each case.\n",
    "CAND_HR = [\n",
    "    \"ECG_HR\", \"HR\", \"ECG/HR\", \"ECG_II_HR\", \"HR_ECG\", \"HR1\"\n",
    "]\n",
    "CAND_SPO2 = [\n",
    "    \"SpO2\", \"SPO2\", \"PLETH_SPO2\", \"PLETH/SpO2\", \"Masimo_SpO2\", \"Saturation\"\n",
    "]\n",
    "CAND_BP = [\n",
    "    # Invasive arterial mean pressure (map/mean)\n",
    "    \"ART\", \"ABP\", \"ART_MBP\", \"ABP_M\", \"ART_Mean\", \"ABP_Mean\", \"ART_MAP\", \"ABP_MAP\",\n",
    "    # Non-invasive mean pressure\n",
    "    \"NBP_Mean\", \"NIBP_M\", \"NIBP_Mean\", \"NBP_MAP\"\n",
    "]\n",
    "\n",
    "# Track sets to quickly \"probe\" VitalDB for case IDs.\n",
    "# We try several common combinations; the first that returns non-empty wins.\n",
    "PROBE_TRACK_SETS = [\n",
    "    [\"ECG_II\", \"ART\"],\n",
    "    [\"ECG\", \"ART\"],\n",
    "    [\"ECG_II\", \"ABP\"],\n",
    "    [\"PLETH\", \"ART\"],\n",
    "    [\"ECG\", \"PLETH\"],\n",
    "    [\"ECG\", \"ABP\"],\n",
    "]\n",
    "\n",
    "# Build `probe` by trying the above sets in order.\n",
    "probe = None\n",
    "for tracks in PROBE_TRACK_SETS:\n",
    "    try:\n",
    "        res = vitaldb.find_cases(tracks)\n",
    "        if res and len(res) > 0:\n",
    "            probe = res\n",
    "            print(f\"Probe OK with tracks {tracks} → {len(res)} case IDs found.\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"[Probe] Failed with {tracks}: {type(e).__name__}: {e}\")\n",
    "\n",
    "if probe is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not build 'probe' with default track sets. \"\n",
    "        \"Inspect a known case and extend CAND_* lists with the actual track names.\"\n",
    "    )\n",
    "\n",
    "# Optional helper to inspect the available track names for a case ID.\n",
    "def inspect_tracks(case_id, limit=50):\n",
    "    \"\"\"\n",
    "    Print the first `limit` track names for a given case, to help refine CAND_* lists.\n",
    "    \"\"\"\n",
    "    vf = vitaldb.VitalFile(int(case_id))\n",
    "    names = vf.get_track_names()\n",
    "    print(f\"Case {case_id} → {len(names)} tracks. First {min(limit, len(names))}:\")\n",
    "    for n in names[:limit]:\n",
    "        print(\"  -\", n)\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vs_ZNOeJqaDZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5c4542f0b3474a34b35f694760757778",
      "936d9abda3f9422e803f1f669b380570",
      "a920e47e90674200800b93617d1c8ce5",
      "aca8b02bb4cd4285b257f695d87ff3cc",
      "95f91f90396045c0a8a514a587e69b25",
      "ab893a82edeb4216b77959f5501e7726",
      "315b802f05ab4b818ba80f1779d9e5e3",
      "4ff337cd66d444fca99baa99f93f6254",
      "36e4a17d853d4b29823b2124cafc6134",
      "80b27a672ac44cf193e3eb4238eb29f1",
      "b37db04d276c46b1a3ef9ea3cc28b245"
     ]
    },
    "id": "Vs_ZNOeJqaDZ",
    "outputId": "0f12ed94-a606-4993-b1bd-56f1485cc422"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STEP 1  VitalDB end-to-end (single cell, strict validation)\n",
    "# - Build probe, conservative smart-pick, Drive cache\n",
    "# - Fast pass at 60 min, optional refine at 15 min\n",
    "# - Strong data validation before counting a subject as valid\n",
    "# - Parallel threads, early-stop, heartbeats & summaries\n",
    "# ==============================================================================\n",
    "\n",
    "import os, time, random, hashlib, threading\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vitaldb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------------------------------------------\n",
    "TARGET_N_CASES       = 1000\n",
    "TARGET_SUBJECTS      = 250\n",
    "\n",
    "# Fast + refine\n",
    "FAST_SCAN_INTERVAL   = 60 * 60      # 60 min\n",
    "REFINE_INTERVAL      = 15 * 60      # 15 min\n",
    "ENABLE_FAST_SCAN     = True\n",
    "ENABLE_REFINE_PASS   = False\n",
    "\n",
    "# Parallelism & pacing\n",
    "MAX_WORKERS          = 8\n",
    "CASE_SOFT_TIMEOUT    = 25\n",
    "PRINT_EVERY_SUBJECTS = 10\n",
    "PRINT_EVERY_SECONDS  = 30\n",
    "SUMMARY_EVERY_CASES  = 25\n",
    "HEARTBEAT_SECONDS    = 15\n",
    "SHUFFLE_CASES        = True\n",
    "\n",
    "# Validation thresholds (tune for your dataset)\n",
    "MIN_SAMPLES          = 6            # minimum rows after resampling\n",
    "MIN_OVERLAP          = 4            # rows where HR & SpO2 both present\n",
    "MIN_COVERAGE         = 0.25         # fraction of non-NaN per vital\n",
    "MIN_INRANGE_FRAC_HR  = 0.70         # fraction of HR values within 20..250\n",
    "MIN_INRANGE_FRAC_SPO2= 0.70         # fraction of SpO2 within 50..100\n",
    "HR_MEDIAN_RANGE      = (30, 150)    # plausible median HR\n",
    "SPO2_MEDIAN_RANGE    = (80, 100)    # plausible median SpO2\n",
    "\n",
    "# Cache on Google Drive\n",
    "PROJECT_SUBDIR       = \"Conference_paper_ICCC_2026\"\n",
    "GDRIVE_BASES         = [\"/content/drive/MyDrive\", \"/content/drive/MyDrive/Apps\"]\n",
    "CACHE_BACKEND        = \"parquet\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Cache helpers\n",
    "# ------------------------------------------------------------------------------\n",
    "def resolve_cache_dir():\n",
    "    for base in GDRIVE_BASES:\n",
    "        if os.path.isdir(base):\n",
    "            return os.path.join(base, PROJECT_SUBDIR)\n",
    "    fallback = os.path.join(\"/content\", PROJECT_SUBDIR)\n",
    "    print(\n",
    "        f\"[Warning] Google Drive not mounted.\\n\"\n",
    "        f\"Using local ephemeral cache: {fallback}\\n\"\n",
    "        f\"To mount in Colab:\\n\"\n",
    "        f\"  from google.colab import drive\\n\"\n",
    "        f\"  drive.mount('/content/drive')\"\n",
    "    )\n",
    "    return fallback\n",
    "\n",
    "CACHE_DIR = resolve_cache_dir()\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "print(\"Cache dir →\", os.path.abspath(CACHE_DIR))\n",
    "\n",
    "def _cache_key(cid, tracks, interval):\n",
    "    key_src = f\"cid={cid}|tracks={','.join(tracks)}|interval={interval}\"\n",
    "    return f\"case_{cid}_{hashlib.md5(key_src.encode('utf-8')).hexdigest()[:12]}\"\n",
    "\n",
    "def cache_paths(cid, tracks, interval):\n",
    "    base = os.path.join(CACHE_DIR, _cache_key(cid, tracks, interval))\n",
    "    return {\"parquet\": base + \".parquet\", \"pickle\": base + \".pkl.gz\", \"tmp\": base + \".tmp\"}\n",
    "\n",
    "def load_from_cache(cid, tracks, interval):\n",
    "    paths = cache_paths(cid, tracks, interval)\n",
    "    if os.path.exists(paths[\"parquet\"]):\n",
    "        try: return pd.read_parquet(paths[\"parquet\"])\n",
    "        except Exception: pass\n",
    "    if os.path.exists(paths[\"pickle\"]):\n",
    "        try: return pd.read_pickle(paths[\"pickle\"], compression=\"gzip\")\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def save_to_cache(df, cid, tracks, interval):\n",
    "    paths = cache_paths(cid, tracks, interval)\n",
    "    tmp_path = paths[\"tmp\"]\n",
    "    try:\n",
    "        if CACHE_BACKEND == \"parquet\":\n",
    "            try:\n",
    "                df.to_parquet(tmp_path)\n",
    "                os.replace(tmp_path, paths[\"parquet\"]); return\n",
    "            except Exception:\n",
    "                pass\n",
    "        df.to_pickle(tmp_path, compression=\"gzip\")\n",
    "        os.replace(tmp_path, paths[\"pickle\"])\n",
    "    finally:\n",
    "        if os.path.exists(tmp_path):\n",
    "            try: os.remove(tmp_path)\n",
    "            except Exception: pass\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Conservative smart selector (regex + negative filters)\n",
    "# ------------------------------------------------------------------------------\n",
    "def smart_pick(tracks, kind):\n",
    "    \"\"\"\n",
    "    Heuristically pick one track of a given kind in {'hr','spo2','map'}.\n",
    "    Conservative filtering to avoid alarms/derived/non-phys channels.\n",
    "    \"\"\"\n",
    "    bad_tokens = [\"alarm\", \"arr\", \"arrhythm\", \"resp\", \"rr\", \"quality\", \"flag\", \"beat-to-beat\", \"status\"]\n",
    "    cands = []\n",
    "    for t in tracks:\n",
    "        n = t.lower()\n",
    "        if any(b in n for b in bad_tokens):\n",
    "            continue\n",
    "\n",
    "        if kind == \"hr\":\n",
    "            if (\"hr\" in n or \"heart\" in n):\n",
    "                score = 0\n",
    "                if \"ecg\" in n: score += 4\n",
    "                if \"/hr\" in n or n.endswith(\"_hr\"): score += 2\n",
    "                if \"calc\" in n or \"derived\" in n: score -= 1\n",
    "                if \"nibp\" in n or \"nbp\" in n: score -= 2\n",
    "                cands.append((score, t))\n",
    "\n",
    "        elif kind == \"spo2\":\n",
    "            if (\"spo2\" in n or \"saturation\" in n):\n",
    "                score = 0\n",
    "                if \"pleth\" in n: score += 1  # hint, but SpO2 is numeric channel\n",
    "                if \"masimo\" in n or \"mindray\" in n or \"solar8000\" in n: score += 1\n",
    "                if \"calc\" in n or \"derived\" in n: score -= 1\n",
    "                cands.append((score, t))\n",
    "\n",
    "        elif kind == \"map\":\n",
    "            # prefer invasive mean first\n",
    "            if (\"art\" in n or \"abp\" in n or \"ibp\" in n or \"a-line\" in n):\n",
    "                if (\"map\" in n or \"mean\" in n or n.endswith(\"_m\")):\n",
    "                    score = 5\n",
    "                    if \"art\" in n or \"abp\" in n: score += 2\n",
    "                    cands.append((score, t))\n",
    "            elif (\"nibp\" in n or \"nbp\" in n):\n",
    "                if (\"map\" in n or \"mean\" in n or n.endswith(\"_m\")):\n",
    "                    score = 1\n",
    "                    cands.append((score, t))\n",
    "\n",
    "    if not cands:\n",
    "        return None\n",
    "    cands.sort(key=lambda x: (-x[0], len(x[1])))\n",
    "    return cands[0][1]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Strict validation of a per-case dataframe\n",
    "# ------------------------------------------------------------------------------\n",
    "def _frac_in_range(s, lo, hi):\n",
    "    s = s.dropna()\n",
    "    if s.empty: return 0.0\n",
    "    return ((s >= lo) & (s <= hi)).mean()\n",
    "\n",
    "def validate_case_df(df):\n",
    "    \"\"\"\n",
    "    Return (True, info) if valid, else (False, reason).\n",
    "    Requires: enough rows, coverage, overlap, plausible medians and in-range fractions.\n",
    "    \"\"\"\n",
    "    cols = [c for c in [\"Heart_Rate\", \"SpO2\", \"Arterial_BP_Mean\"] if c in df.columns]\n",
    "    if len(cols) < 2:\n",
    "        return False, \"too-few-cols\"\n",
    "\n",
    "    n = len(df)\n",
    "    if n < MIN_SAMPLES:\n",
    "        return False, \"too-short\"\n",
    "\n",
    "    # coverage per vital\n",
    "    cov_hr = df[\"Heart_Rate\"].notna().mean() if \"Heart_Rate\" in df else 0.0\n",
    "    cov_s  = df[\"SpO2\"].notna().mean() if \"SpO2\" in df else 0.0\n",
    "    if cov_hr < MIN_COVERAGE or cov_s < MIN_COVERAGE:\n",
    "        return False, \"insufficient-coverage\"\n",
    "\n",
    "    # overlap rows\n",
    "    overlap = ((~df[\"Heart_Rate\"].isna()) & (~df[\"SpO2\"].isna())).sum()\n",
    "    if overlap < MIN_OVERLAP:\n",
    "        return False, \"insufficient-overlap\"\n",
    "\n",
    "    # physiological sanity\n",
    "    frac_hr_ok = _frac_in_range(df[\"Heart_Rate\"], 20, 250) if \"Heart_Rate\" in df else 0.0\n",
    "    frac_s_ok  = _frac_in_range(df[\"SpO2\"], 50, 100) if \"SpO2\" in df else 0.0\n",
    "    if frac_hr_ok < MIN_INRANGE_FRAC_HR or frac_s_ok < MIN_INRANGE_FRAC_SPO2:\n",
    "        return False, \"out-of-range\"\n",
    "\n",
    "    med_hr = np.nanmedian(df[\"Heart_Rate\"].values) if \"Heart_Rate\" in df else np.nan\n",
    "    med_s  = np.nanmedian(df[\"SpO2\"].values) if \"SpO2\" in df else np.nan\n",
    "    if not (HR_MEDIAN_RANGE[0] <= med_hr <= HR_MEDIAN_RANGE[1]):\n",
    "        return False, \"hr-median-implausible\"\n",
    "    if not (SPO2_MEDIAN_RANGE[0] <= med_s <= SPO2_MEDIAN_RANGE[1]):\n",
    "        return False, \"spo2-median-implausible\"\n",
    "\n",
    "    # optional: MAP sanity if present (do not fail hard; only tag)\n",
    "    if \"Arterial_BP_Mean\" in df:\n",
    "        frac_map_ok = _frac_in_range(df[\"Arterial_BP_Mean\"], 20, 200)\n",
    "        # we don't require MAP; if wildly off, we could drop the column:\n",
    "        if frac_map_ok < 0.5:\n",
    "            df[\"Arterial_BP_Mean\"] = np.where(\n",
    "                (df[\"Arterial_BP_Mean\"] >= 20) & (df[\"Arterial_BP_Mean\"] <= 200),\n",
    "                df[\"Arterial_BP_Mean\"],\n",
    "                np.nan\n",
    "            )\n",
    "\n",
    "    # info summary to print on FOUND\n",
    "    info = {\n",
    "        \"rows\": n,\n",
    "        \"cov_hr\": cov_hr,\n",
    "        \"cov_spo2\": cov_s,\n",
    "        \"overlap\": int(overlap),\n",
    "        \"med_hr\": float(med_hr),\n",
    "        \"med_spo2\": float(med_s),\n",
    "        \"frac_hr_ok\": float(frac_hr_ok),\n",
    "        \"frac_spo2_ok\": float(frac_s_ok),\n",
    "    }\n",
    "    return True, info\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Build `probe`\n",
    "# ------------------------------------------------------------------------------\n",
    "PROBE_TRACK_SETS = [\n",
    "    [\"ECG_II\", \"ART\"], [\"ECG\", \"ART\"], [\"ECG_II\", \"ABP\"],\n",
    "    [\"PLETH\", \"ART\"], [\"ECG\", \"PLETH\"], [\"ECG\", \"ABP\"],\n",
    "]\n",
    "probe = None\n",
    "for tracks in PROBE_TRACK_SETS:\n",
    "    try:\n",
    "        res = vitaldb.find_cases(tracks)\n",
    "        if res and len(res) > 0:\n",
    "            probe = res\n",
    "            print(f\"Probe OK with tracks {tracks} → {len(res)} case IDs.\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"[Probe] Failed with {tracks}: {type(e).__name__}: {e}\")\n",
    "if probe is None:\n",
    "    raise RuntimeError(\"Could not build 'probe'. Adjust PROBE_TRACK_SETS.\")\n",
    "\n",
    "all_case_ids = [int(x) for x in probe]\n",
    "case_ids = all_case_ids[:TARGET_N_CASES]\n",
    "if SHUFFLE_CASES:\n",
    "    random.shuffle(case_ids)\n",
    "\n",
    "print(f\"Total cases from probe: {len(all_case_ids)}\")\n",
    "print(f\"Will inspect up to: {len(case_ids)} cases\\n\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Per-case worker (parametric interval) + strict validation\n",
    "# ------------------------------------------------------------------------------\n",
    "def process_case_with_interval(cid, interval):\n",
    "    \"\"\"\n",
    "    Return (cid, df_case or None, src_str, reason_or_info).\n",
    "    On success: src_str in {'cache','download'} and reason_or_info is a dict with metrics.\n",
    "    On skip: src_str is None and reason_or_info is a string reason.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vf = vitaldb.VitalFile(cid)\n",
    "        case_tracks = vf.get_track_names()\n",
    "\n",
    "        hr_track   = smart_pick(case_tracks, \"hr\")\n",
    "        spo2_track = smart_pick(case_tracks, \"spo2\")\n",
    "        map_track  = smart_pick(case_tracks, \"map\")\n",
    "\n",
    "        if (hr_track is None) or (spo2_track is None):\n",
    "            return cid, None, None, \"skip-missing-tracks\"\n",
    "\n",
    "        selected = [t for t in [hr_track, spo2_track, map_track] if t is not None]\n",
    "\n",
    "        # cache first\n",
    "        df_case = load_from_cache(cid, selected, interval)\n",
    "        src = \"cache\" if df_case is not None else \"download\"\n",
    "\n",
    "        if df_case is None:\n",
    "            t_start = time.time()\n",
    "            df_case = vf.to_pandas(selected, interval=interval)\n",
    "            if df_case is None or df_case.empty:\n",
    "                return cid, None, None, \"empty\"\n",
    "\n",
    "            rename_map = {hr_track: \"Heart_Rate\", spo2_track: \"SpO2\"}\n",
    "            if map_track is not None:\n",
    "                rename_map[map_track] = \"Arterial_BP_Mean\"\n",
    "            df_case = df_case.rename(columns=rename_map)\n",
    "\n",
    "            keep_cols = [c for c in [\"Heart_Rate\", \"SpO2\", \"Arterial_BP_Mean\"] if c in df_case.columns]\n",
    "            if len(keep_cols) < 2:\n",
    "                return cid, None, None, \"too-few-cols\"\n",
    "\n",
    "            df_case = df_case.reset_index().rename(columns={\"index\": \"charttime\"})\n",
    "            df_case[\"subject_id\"] = cid\n",
    "            df_case = df_case.dropna(subset=keep_cols, how=\"all\")\n",
    "            df_case = df_case[[\"subject_id\", \"charttime\"] + keep_cols]\n",
    "            if df_case.empty:\n",
    "                return cid, None, None, \"all-nan\"\n",
    "\n",
    "            slow = (time.time() - t_start) > CASE_SOFT_TIMEOUT\n",
    "\n",
    "            # strict validation\n",
    "            ok, info = validate_case_df(df_case)\n",
    "            if not ok:\n",
    "                return cid, None, None, info  # info is reason string\n",
    "\n",
    "            # cache best-effort\n",
    "            try:\n",
    "                save_to_cache(df_case, cid, selected, interval)\n",
    "            except Exception as ce:\n",
    "                tqdm.write(f\"[Cache] write failed for case {cid}: {type(ce).__name__}: {ce}\")\n",
    "\n",
    "            # tag slow if needed\n",
    "            if slow and isinstance(info, dict):\n",
    "                info = {**info, \"slow\": True}\n",
    "\n",
    "            return cid, df_case, src, info\n",
    "\n",
    "        else:\n",
    "            # strict validation on cached data too\n",
    "            ok, info = validate_case_df(df_case)\n",
    "            if not ok:\n",
    "                return cid, None, None, info\n",
    "            return cid, df_case, src, info\n",
    "\n",
    "    except Exception as e:\n",
    "        return cid, None, None, f\"error:{type(e).__name__}\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Parallel pass with early-stop + strict validation\n",
    "# ------------------------------------------------------------------------------\n",
    "def run_parallel_pass(interval, target_subjects, tag=\"FAST\"):\n",
    "    found = []\n",
    "    skip_counts = Counter()\n",
    "    t0 = time.time()\n",
    "    last_log_time = t0\n",
    "    last_log_subjects = 0\n",
    "    last_heartbeat = t0\n",
    "    total = len(case_ids)\n",
    "    cases_seen = 0\n",
    "    stop_flag = threading.Event()\n",
    "\n",
    "    def heartbeat():\n",
    "        nonlocal last_heartbeat\n",
    "        now = time.time()\n",
    "        if (now - last_heartbeat) >= HEARTBEAT_SECONDS:\n",
    "            pct = (cases_seen / max(1,total)) * 100.0\n",
    "            top = \", \".join(f\"{k}:{v}\" for k,v in skip_counts.most_common(3)) or \"—\"\n",
    "            tqdm.write(f\"[Heartbeat] processed={cases_seen}/{total} ({pct:.1f}%) | valid={len(found)} | skips: {top}\")\n",
    "            last_heartbeat = now\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futures = {ex.submit(process_case_with_interval, cid, interval): cid for cid in case_ids}\n",
    "        with tqdm(total=total, desc=f\"{tag} pass (interval={interval//60}min) x{MAX_WORKERS}\") as pbar:\n",
    "            try:\n",
    "                for fut in as_completed(futures):\n",
    "                    if stop_flag.is_set():\n",
    "                        break\n",
    "                    cid = futures[fut]\n",
    "                    cid_out, df_case, src, meta = fut.result()\n",
    "                    pbar.update(1)\n",
    "                    cases_seen += 1\n",
    "\n",
    "                    if df_case is None:\n",
    "                        reason = meta if isinstance(meta, str) else \"unknown\"\n",
    "                        skip_counts[reason] += 1\n",
    "                        if SUMMARY_EVERY_CASES and cases_seen % SUMMARY_EVERY_CASES == 0:\n",
    "                            top = \", \".join(f\"{k}:{v}\" for k,v in skip_counts.most_common(6))\n",
    "                            tqdm.write(f\"[Summary] processed={cases_seen} | valid={len(found)} | skips: {top}\")\n",
    "                        heartbeat()\n",
    "                        continue\n",
    "\n",
    "                    found.append((cid_out, df_case))\n",
    "                    # meta is dict with validation info\n",
    "                    info = \", \".join([\n",
    "                        f\"rows={meta.get('rows')}\",\n",
    "                        f\"cov_hr={meta.get('cov_hr'):.2f}\",\n",
    "                        f\"cov_spo2={meta.get('cov_spo2'):.2f}\",\n",
    "                        f\"overlap={meta.get('overlap')}\",\n",
    "                        f\"med_hr={meta.get('med_hr'):.1f}\",\n",
    "                        f\"med_spo2={meta.get('med_spo2'):.1f}\",\n",
    "                    ])\n",
    "                    if meta.get(\"slow\", False):\n",
    "                        info += \" | slow\"\n",
    "                    tqdm.write(f\"[FOUND] subject_id={cid_out} | {info} | src={src} | total_valid={len(found)}\")\n",
    "\n",
    "                    now = time.time()\n",
    "                    if len(found) >= target_subjects:\n",
    "                        tqdm.write(f\"\\nReached target of {target_subjects} subjects – stopping early & cancelling remaining.\")\n",
    "                        stop_flag.set()\n",
    "                        for f in futures:\n",
    "                            if not f.done():\n",
    "                                f.cancel()\n",
    "                        break\n",
    "\n",
    "                    by_subj = (PRINT_EVERY_SUBJECTS is not None and len(found) > 0 and\n",
    "                               (len(found) - last_log_subjects) >= PRINT_EVERY_SUBJECTS)\n",
    "                    by_sec  = (PRINT_EVERY_SECONDS is not None and (now - last_log_time) >= PRINT_EVERY_SECONDS)\n",
    "                    if by_subj or by_sec:\n",
    "                        elapsed = now - t0\n",
    "                        rate = len(found) / elapsed if elapsed > 0 else 0.0\n",
    "                        pct = (cases_seen / max(1,total)) * 100.0\n",
    "                        tqdm.write(\n",
    "                            f\"[Progress] valid={len(found)}/{target_subjects} \"\n",
    "                            f\"({len(found)/max(1,target_subjects):.0%}) | \"\n",
    "                            f\"processed={cases_seen}/{total} ({pct:.1f}%) | \"\n",
    "                            f\"elapsed={elapsed/60:.1f}m | rate={rate:.2f} subj/s\"\n",
    "                        )\n",
    "                        last_log_time = now\n",
    "                        last_log_subjects = len(found)\n",
    "                    heartbeat()\n",
    "            finally:\n",
    "                ex.shutdown(cancel_futures=True)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tqdm.write(f\"[{tag}] Done in {elapsed/60:.1f} minutes. Found {len(found)} valid subjects.\")\n",
    "    return found, skip_counts\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# RUN\n",
    "# ------------------------------------------------------------------------------\n",
    "if MAX_WORKERS <= 0:\n",
    "    raise RuntimeError(\"Set MAX_WORKERS > 0 for the speed-optimized path.\")\n",
    "\n",
    "first_interval = FAST_SCAN_INTERVAL if ENABLE_FAST_SCAN else REFINE_INTERVAL\n",
    "found_fast, skip_counts = run_parallel_pass(first_interval, TARGET_SUBJECTS, tag=\"FAST\" if ENABLE_FAST_SCAN else \"MAIN\")\n",
    "\n",
    "if len(found_fast) == 0:\n",
    "    top = \", \".join(f\"{k}:{v}\" for k,v in skip_counts.most_common(10)) or \"—\"\n",
    "    raise RuntimeError(f\"No valid subjects found. Skip reasons: {top}\")\n",
    "\n",
    "df_wide = pd.concat([df for _, df in found_fast], ignore_index=True)\n",
    "print(f\"\\nBuilt 'df_wide' (interval={first_interval//60}min) with shape: {df_wide.shape}\")\n",
    "print(df_wide.head())\n",
    "\n",
    "# Optional refine at 15 min for only the found subjects\n",
    "if ENABLE_REFINE_PASS and ENABLE_FAST_SCAN and (REFINE_INTERVAL != first_interval):\n",
    "    tqdm.write(\"\\n[REFINE] Re-fetching found subjects at 15-min interval…\")\n",
    "    subject_ids = [cid for cid, _ in found_fast]\n",
    "\n",
    "    def refine_case(cid):\n",
    "        _, df_case, src, meta = process_case_with_interval(cid, REFINE_INTERVAL)\n",
    "        return cid, df_case, src, meta\n",
    "\n",
    "    refined, skip_ref = [], Counter()\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futures = {ex.submit(refine_case, cid): cid for cid in subject_ids}\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures), desc=f\"REFINE pass (interval={REFINE_INTERVAL//60}min)\"):\n",
    "            cid = futures[fut]\n",
    "            cid_out, df_case, src, meta = fut.result()\n",
    "            if df_case is None:\n",
    "                reason = meta if isinstance(meta, str) else \"unknown\"\n",
    "                skip_ref[reason] += 1\n",
    "            else:\n",
    "                tqdm.write(f\"[REFINE-FOUND] subject_id={cid_out} | rows={len(df_case)} | src={src}\")\n",
    "                refined.append(df_case)\n",
    "\n",
    "    if refined:\n",
    "        df_wide = pd.concat(refined, ignore_index=True)\n",
    "        print(f\"[REFINE] Rebuilt 'df_wide' (interval={REFINE_INTERVAL//60}min) with shape: {df_wide.shape}\")\n",
    "        print(df_wide.head())\n",
    "    else:\n",
    "        top = \", \".join(f\"{k}:{v}\" for k,v in skip_ref.most_common(10)) or \"—\"\n",
    "        tqdm.write(f\"[REFINE] No subjects refined. Skip reasons: {top}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f58404",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "62f58404",
    "outputId": "6b03f48a-0803-4988-d3ac-ff2a483ec826"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VITALDB - STEP 2: TIME-SERIES PREPROCESSING AND IMPUTATION\n",
    "# ==============================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if 'df_wide' in locals():\n",
    "    print(\"--- Starting time-series preprocessing ---\")\n",
    "\n",
    "    # 1. Convert 'charttime' column to datetime objects\n",
    "    df_wide['charttime'] = pd.to_datetime(df_wide['charttime'])\n",
    "    print(\"-> Converted 'charttime' to datetime objects.\")\n",
    "\n",
    "    # 2. Resample and impute data for each patient\n",
    "    # We will process each patient individually to not mix their data\n",
    "    processed_patients = []\n",
    "\n",
    "    # Use .groupby() to iterate over each patient's data\n",
    "    for patient_id, group in df_wide.groupby('subject_id'):\n",
    "        # Set the time column as the index for time-based operations\n",
    "        group = group.set_index('charttime').drop('subject_id', axis=1)\n",
    "\n",
    "        # Resample to a fixed frequency (e.g., every 15 minutes) and take the mean\n",
    "        # This creates a uniform timeline for all patients\n",
    "        group_resampled = group.resample('15T').mean()\n",
    "\n",
    "        # Impute missing values using forward-fill, then backward-fill\n",
    "        group_imputed = group_resampled.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        # Add the patient_id back\n",
    "        group_imputed['subject_id'] = patient_id\n",
    "\n",
    "        processed_patients.append(group_imputed)\n",
    "\n",
    "    # Concatenate all processed patient dataframes back into one\n",
    "    df_processed = pd.concat(processed_patients).reset_index()\n",
    "    print(\"-> Resampled to a 15-minute frequency and imputed missing values.\")\n",
    "\n",
    "    # 3. Handle any fully-NaN patients that might remain and scale features\n",
    "    df_processed.dropna(inplace=True) # Drop patients with no measurements at all\n",
    "\n",
    "    vital_cols = [col for col in df_processed.columns if col not in ['subject_id', 'charttime']]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_processed[vital_cols] = scaler.fit_transform(df_processed[vital_cols])\n",
    "    print(\"-> Scaled vital sign features.\")\n",
    "\n",
    "    # 4. Display final result\n",
    "    print(\"\\n--- Preprocessing complete. Data is now clean and uniform. ---\")\n",
    "    display(df_processed.info())\n",
    "    display(df_processed.head())\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Wide-format dataframe 'df_wide' not found. Please run Step 1 successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7R1eNHrsQ979",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R1eNHrsQ979",
    "outputId": "a5d10d51-0838-4e9b-dc62-e58b2638a879"
   },
   "outputs": [],
   "source": [
    "#Save the fully processed VitalDB dataframe used by the AE\n",
    "processed_clinical_path = \"/content/drive/MyDrive/Conference_paper_ICCC_2026/vitaldb_df_processed_final.parquet\"\n",
    "df_processed.to_parquet(processed_clinical_path, index=False)\n",
    "print(\"✅ Saved VitalDB processed clinical dataframe to:\", processed_clinical_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae313ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ae313ee",
    "outputId": "3d8add70-c540-4746-c95d-409c57e635aa"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SAVE THE PROCESSED DATAFRAME (Corrected Variable Name)\n",
    "# ==============================================================================\n",
    "\n",
    "# The variable created by our last preprocessing script is 'df_processed'\n",
    "if 'df_processed' in locals():\n",
    "    # Define the path where the file will be saved\n",
    "    save_path = '/content/drive/MyDrive/Conference_paper_ICCC_2026/df_processed_final.parquet'\n",
    "\n",
    "    # Save the dataframe to a Parquet file\n",
    "    print(f\"Saving the processed dataframe ('df_processed') to {save_path}...\")\n",
    "    df_processed.to_parquet(save_path)\n",
    "    print(\"Save complete!\")\n",
    "else:\n",
    "    print(\"ERROR: Dataframe 'df_processed' not found. Please ensure the preprocessing cell has been run successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb888f25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eb888f25",
    "outputId": "36caf33c-9fe1-456c-efd4-140a77f0ef19"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VITALDB - STEP 3: UNSUPERVISED ANOMALY DETECTION WITH LSTM AUTOENCODER\n",
    "# (now using VitalDB-derived df_processed)\n",
    "# ==============================================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Helper Function to create time-series sequences ---\n",
    "def create_sequences(X_data, y_data, time_steps=10):\n",
    "    \"\"\"Creates time-series sequences from 2D data.\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        v = X_data[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        # The y_data is just a placeholder here, not used for training\n",
    "        ys.append(y_data[i + time_steps - 1])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# --- Main Logic ---\n",
    "if 'df_processed' in locals():\n",
    "    # 1. Prepare Data for the Autoencoder\n",
    "    print(\"--- Preparing data for Autoencoder ---\")\n",
    "\n",
    "    # Select only the vital sign columns for training\n",
    "    # With VitalDB we may have fewer vital signs than the original MIMIC-IV demo.\n",
    "    # We therefore select only the columns that are actually present in df_processed.\n",
    "    candidate_vital_cols = [\n",
    "        'Arterial_BP_Mean',\n",
    "        'Heart_Rate',\n",
    "        'SpO2',\n",
    "        'Arterial_BP_Diastolic',\n",
    "        'Arterial_BP_Systolic',\n",
    "        'Respiratory_Rate',\n",
    "        'Temperature_C',\n",
    "    ]\n",
    "    vital_cols = [c for c in candidate_vital_cols if c in df_processed.columns]\n",
    "    print(\"Using vital columns for AE:\", vital_cols)\n",
    "    if len(vital_cols) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No valid vital sign columns found in df_processed. \"\n",
    "            \"Please check preprocessing / column names.\"\n",
    "        )\n",
    "\n",
    "    data_for_model = df_processed[vital_cols].values\n",
    "\n",
    "    # Create sequences. We don't need the 'y' labels for autoencoder training.\n",
    "    TIME_STEPS = 24  # Using a window of 24 samples (e.g., 6 hours if data is every 15 mins)\n",
    "    X_sequences, _ = create_sequences(\n",
    "        data_for_model,\n",
    "        data_for_model[:, 0],\n",
    "        time_steps=TIME_STEPS\n",
    "    )\n",
    "    print(f\"Created {X_sequences.shape[0]} sequences of shape {X_sequences.shape[1:]}\")\n",
    "\n",
    "    # Split into training and testing sets. We will test the model's ability to reconstruct unseen data.\n",
    "    X_train, X_test = train_test_split(\n",
    "        X_sequences,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Test data shape: {X_test.shape}\")\n",
    "\n",
    "    # 2. Build the LSTM Autoencoder Model\n",
    "    n_features = X_train.shape[2]\n",
    "    timesteps = X_train.shape[1]\n",
    "\n",
    "    print(\"\\n--- Building LSTM Autoencoder Model ---\")\n",
    "    inputs = Input(shape=(timesteps, n_features))\n",
    "    # Encoder\n",
    "    encoded = LSTM(64, activation='relu')(inputs)\n",
    "    # Bottleneck\n",
    "    bottleneck = RepeatVector(timesteps)(encoded)\n",
    "    # Decoder\n",
    "    decoded = LSTM(64, activation='relu', return_sequences=True)(bottleneck)\n",
    "    # Output Layer\n",
    "    outputs = TimeDistributed(Dense(n_features))(decoded)\n",
    "\n",
    "    autoencoder = Model(inputs, outputs)\n",
    "    autoencoder.compile(optimizer='adam', loss='mae')  # Using Mean Absolute Error as the loss function\n",
    "    autoencoder.summary()\n",
    "\n",
    "    # 3. Train the Autoencoder\n",
    "    print(\"\\n--- Training Autoencoder on normal patterns ---\")\n",
    "    history = autoencoder.fit(\n",
    "        X_train, X_train,  # The model learns to predict its own input\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 4. Detect Anomalies based on Reconstruction Error\n",
    "    print(\"\\n--- Detecting anomalies based on reconstruction error ---\")\n",
    "    X_test_pred = autoencoder.predict(X_test)\n",
    "\n",
    "    # Reconstruction error per sample (media su time e feature)\n",
    "    test_mae_loss = np.mean(np.abs(X_test_pred - X_test), axis=(1, 2))  # shape: (n_samples,)\n",
    "\n",
    "    # Threshold sul 95° percentile dei sample-level errors\n",
    "    threshold = np.quantile(test_mae_loss, 0.95)\n",
    "    print(f\"Reconstruction error threshold for anomalies set to: {threshold:.3f}\")\n",
    "\n",
    "    # Indici delle anomalie\n",
    "    anomaly_indices = np.where(test_mae_loss > threshold)[0]\n",
    "    print(f\"Found {len(anomaly_indices)} potential anomalies in the test set.\")\n",
    "\n",
    "\n",
    "    # 5. Visualize a detected anomaly\n",
    "    if len(anomaly_indices) > 0:\n",
    "        print(\"\\n--- Visualizing a detected anomaly ---\")\n",
    "        idx_to_plot = anomaly_indices[0]\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        # Plot the original signal (e.g., Heart Rate, which is column index 3 in vital_cols)\n",
    "        hr_idx = vital_cols.index(\"Heart_Rate\")  # se presente\n",
    "        plt.plot(X_test[idx_to_plot, :, hr_idx], label='Original Heart Rate')\n",
    "        plt.plot(X_test_pred[idx_to_plot, :, hr_idx], label='Reconstructed Heart Rate', linestyle='--')\n",
    "        plt.title('Example of an Anomalous Sequence (High Reconstruction Error)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Processed dataframe 'df_processed' not found. Please run the preprocessing steps first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_q_Aj6Erco8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      "899ad84ae73d4d5891a98d9a128db75f",
      "b117d72294f7417bb9762a278107fca5",
      "cd4bc3d9a3c04b6dbad129e7bd22d970",
      "bf35cdafc4a34443ba20b54d0ab06716",
      "045d0c06345441bfac5d9e6d6da107a3",
      "795b65d7f23940b3a620c8a207e089f7",
      "884f46b4d6c54a0eb7d6870625fb3bf4",
      "0a6082aaccf141e59200b9f272dd145e",
      "20a25de6f6c44b958cc847f61bedf97e",
      "c7aee10c731647fd9d02944670c67fc8",
      "e7e8e44731c1403c8683ee6d2e08821b"
     ]
    },
    "id": "_q_Aj6Erco8f",
    "outputId": "52523654-3681-4e67-de84-b4a28606dbf6"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VITALDB – GLOBAL AE ERRORS ON TEST SET\n",
    "# ==============================================================================\n",
    "\n",
    "# We assume X_test is the VitalDB test sequences used for AE evaluation\n",
    "# (shape: [N_test, TIME_STEPS, n_features])\n",
    "\n",
    "print(\"Computing AE reconstruction errors on full VitalDB test set...\")\n",
    "\n",
    "X_cli_test_full = X_test  # rename for clarity in downstream fusion evaluation\n",
    "\n",
    "# Reconstruct in batches (if dataset is large)\n",
    "from tqdm.auto import tqdm\n",
    "BATCH_SIZE_AE = 256\n",
    "\n",
    "def predict_ae_batched(model, X, batch_size=256, desc=\"AE inference\"):\n",
    "    outs = []\n",
    "    iterator = range(0, len(X), batch_size)\n",
    "    for i in tqdm(iterator, desc=desc, leave=False):\n",
    "        outs.append(model.predict(X[i:i+batch_size], verbose=0))\n",
    "    return np.concatenate(outs, axis=0)\n",
    "\n",
    "X_cli_recon_full = predict_ae_batched(autoencoder, X_cli_test_full, batch_size=BATCH_SIZE_AE)\n",
    "\n",
    "clin_errors_full = np.mean(np.abs(X_cli_recon_full - X_cli_test_full), axis=(1, 2))\n",
    "\n",
    "print(f\"VitalDB test sequences: {len(clin_errors_full)}\")\n",
    "print(f\"AE error mean={clin_errors_full.mean():.4f}, std={clin_errors_full.std():.4f}\")\n",
    "print(f\"clinical_threshold (from train/val) = {clinical_threshold:.4f}\")\n",
    "\n",
    "# Simple binary anomaly flag for scenarios:\n",
    "# 0 = low error, 1 = high error w.r.t. calibrated threshold\n",
    "clin_flag_full = (clin_errors_full > clinical_threshold).astype(int)\n",
    "print(\"clin_flag_full counts (0=low-error, 1=high-error):\", np.bincount(clin_flag_full))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1bce5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "39e1bce5",
    "outputId": "b3f53d60-d62a-4dfc-e348-d79b8344632f"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VITALDB - STEP 4: ANALYSIS OF DETECTED ANOMALIES\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # optional, for nicer histograms\n",
    "\n",
    "# Check if the results from the autoencoder training cell exist\n",
    "if 'autoencoder' in locals() and 'X_test' in locals():\n",
    "    print(\"--- Analyzing the results of the LSTM Autoencoder ---\")\n",
    "\n",
    "    # 1. Recalculate reconstruction error on the test set (sample-level)\n",
    "    X_test_pred = autoencoder.predict(X_test)\n",
    "    # One scalar error per sequence: mean over time and features\n",
    "    sample_errors = np.mean(np.abs(X_test_pred - X_test), axis=(1, 2))  # shape: (n_samples,)\n",
    "\n",
    "    # 2. Plot the distribution of reconstruction errors\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(sample_errors, bins=50, kde=True)\n",
    "    plt.xlabel(\"Mean Absolute Error (per sequence)\")\n",
    "    plt.ylabel(\"Number of Sequences\")\n",
    "    plt.title(\"Distribution of Reconstruction Errors on Test Set\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Define a threshold and identify anomalies\n",
    "    threshold = np.quantile(sample_errors, 0.95)\n",
    "    print(f\"\\nReconstruction error threshold for anomalies set to: {threshold:.4f} (95th percentile)\")\n",
    "\n",
    "    anomaly_indices = np.where(sample_errors > threshold)[0]\n",
    "    print(f\"Found {len(anomaly_indices)} potential anomalies in the test set \"\n",
    "          f\"({len(anomaly_indices) / len(X_test) * 100:.2f}% of test data).\")\n",
    "\n",
    "    # 4. Visualize one of the detected anomalies\n",
    "    if len(anomaly_indices) > 0:\n",
    "        print(\"\\n--- Visualizing a top detected anomaly ---\")\n",
    "\n",
    "        # Choose the anomaly with the highest reconstruction error\n",
    "        top_anomaly_idx = anomaly_indices[np.argmax(sample_errors[anomaly_indices])]\n",
    "\n",
    "        # Find the index of Heart_Rate in the current vital_cols, fallback to 0 if not present\n",
    "        if \"Heart_Rate\" in vital_cols:\n",
    "            hr_idx = vital_cols.index(\"Heart_Rate\")\n",
    "        else:\n",
    "            print(\"Warning: 'Heart_Rate' not found in vital_cols, using the first feature instead.\")\n",
    "            hr_idx = 0\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(X_test[top_anomaly_idx, :, hr_idx], label=f'Original {vital_cols[hr_idx]}')\n",
    "        plt.plot(X_test_pred[top_anomaly_idx, :, hr_idx],\n",
    "                 label=f'Reconstructed {vital_cols[hr_idx]}',\n",
    "                 linestyle='--')\n",
    "        plt.title(f'Example of a Detected Anomaly (Sequence Index: {top_anomaly_idx})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Autoencoder results not found. Please re-run the training cell (Step 3) successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab04ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "d8ab04ed",
    "outputId": "1507969e-f39b-4b3a-c922-bfc3bff26244"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FINAL ANALYSIS: FEATURE-LEVEL RECONSTRUCTION ERROR (SHAP Alternative)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assicuriamoci che i risultati dell'autoencoder esistano\n",
    "if 'autoencoder' in locals() and 'X_test' in locals():\n",
    "    # Usiamo lo stesso indice dell'anomalia che abbiamo visualizzato prima\n",
    "    if 'top_anomaly_idx' in locals():\n",
    "\n",
    "        print(f\"--- Analyzing feature contribution for anomaly index: {top_anomaly_idx} ---\")\n",
    "\n",
    "        # Prendiamo la sequenza originale e quella ricostruita\n",
    "        original_sequence = X_test[top_anomaly_idx]\n",
    "        reconstructed_sequence = X_test_pred[top_anomaly_idx]\n",
    "\n",
    "        # Calcoliamo l'errore assoluto medio per ogni feature lungo i passi temporali\n",
    "        feature_errors = np.mean(np.abs(original_sequence - reconstructed_sequence), axis=0)\n",
    "\n",
    "        # Creiamo un DataFrame per una facile visualizzazione\n",
    "        error_df = pd.DataFrame({\n",
    "            'Feature': vital_cols,\n",
    "            'Reconstruction_Error': feature_errors\n",
    "        }).sort_values(by='Reconstruction_Error', ascending=False)\n",
    "\n",
    "        # Visualizziamo gli errori\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='Reconstruction_Error', y='Feature', data=error_df, palette='viridis')\n",
    "        plt.title(f'Feature Contribution to Anomaly Score (Sequence {top_anomaly_idx})', fontsize=16)\n",
    "        plt.xlabel('Mean Absolute Error', fontsize=12)\n",
    "        plt.ylabel('Vital Sign Feature', fontsize=12)\n",
    "        plt.grid(axis='x')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\n--- Interpretation ---\")\n",
    "        display(error_df)\n",
    "        print(\"\\nThe feature(s) with the highest reconstruction error are the primary drivers of this anomaly.\")\n",
    "\n",
    "    else:\n",
    "        print(\"No anomaly was previously identified to analyze.\")\n",
    "else:\n",
    "    print(\"ERROR: Autoencoder results not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc2df3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "40bc2df3",
    "outputId": "b0b76079-8953-4502-f579-b130b0a5022d"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VITALDB - FINAL EXPERIMENT: DETECTING A SYNTHETIC SENSOR FAULT\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if the required variables from previous steps exist\n",
    "if 'autoencoder' in locals() and 'X_test' in locals():\n",
    "    print(\"--- Starting Synthetic Anomaly Detection Test ---\")\n",
    "\n",
    "    # 1. Recompute reconstruction errors on the test set (one scalar per sequence)\n",
    "    X_test_pred = autoencoder.predict(X_test, verbose=0)\n",
    "    sample_errors = np.mean(np.abs(X_test_pred - X_test), axis=(1, 2))  # shape: (n_samples,)\n",
    "\n",
    "    # 2. Find a \"normal\" sequence from the test set (with the lowest reconstruction error)\n",
    "    normal_sequence_idx = int(np.argmin(sample_errors))\n",
    "    original_normal_sequence = X_test[normal_sequence_idx]\n",
    "\n",
    "    # Calculate its original low error\n",
    "    original_normal_pred = autoencoder.predict(\n",
    "        np.expand_dims(original_normal_sequence, axis=0),\n",
    "        verbose=0\n",
    "    )\n",
    "    original_error = np.mean(np.abs(original_normal_pred - original_normal_sequence))\n",
    "    print(f\"Selected a normal sequence (index {normal_sequence_idx}) with a low \"\n",
    "          f\"reconstruction error of: {original_error:.4f}\")\n",
    "\n",
    "    # 3. Create a synthetic anomaly: a sensor fault on SpO2\n",
    "    faulty_sequence = original_normal_sequence.copy()\n",
    "\n",
    "    # Determine the index of SpO2 in the current vital_cols\n",
    "    if \"SpO2\" in vital_cols:\n",
    "        spo2_index = vital_cols.index(\"SpO2\")\n",
    "    else:\n",
    "        print(\"Warning: 'SpO2' not found in vital_cols. Using the last feature as a proxy.\")\n",
    "        spo2_index = len(vital_cols) - 1\n",
    "\n",
    "    # Simulate the SpO2 sensor flat-lining at a very low value for 5 time steps\n",
    "    # (values are in scaled space, so -3 is a strong deviation)\n",
    "    start_fault = 10\n",
    "    end_fault = min(start_fault + 5, faulty_sequence.shape[0])\n",
    "    faulty_sequence[start_fault:end_fault, spo2_index] = -3.0\n",
    "    print(\"\\n-> Injected a synthetic SpO2 sensor fault into the normal sequence.\")\n",
    "\n",
    "    # 4. Test the model on the faulty sequence\n",
    "    faulty_sequence_reshaped = np.expand_dims(faulty_sequence, axis=0)\n",
    "    reconstructed_faulty_sequence = autoencoder.predict(faulty_sequence_reshaped, verbose=0)\n",
    "\n",
    "    # 5. Compare the reconstruction error\n",
    "    faulty_error = np.mean(np.abs(reconstructed_faulty_sequence - faulty_sequence))\n",
    "    print(f\"Reconstruction error on the faulty sequence: {faulty_error:.4f}\")\n",
    "    if faulty_error > original_error * 2:\n",
    "        print(\"SUCCESS: The model clearly reacts to the synthetic fault with a much higher error.\")\n",
    "    else:\n",
    "        print(\"Note: The error increased, but not dramatically. You may adjust the fault magnitude or window.\")\n",
    "\n",
    "    # 6. Visualize the result on the SpO2 channel\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(faulty_sequence[:, spo2_index],\n",
    "             label='Original SpO2 with Fault',\n",
    "             marker='o')\n",
    "    plt.plot(reconstructed_faulty_sequence[0, :, spo2_index],\n",
    "             label='Reconstructed SpO2',\n",
    "             linestyle='--')\n",
    "    plt.title('Model Response to a Synthetic SpO2 Sensor Fault')\n",
    "    plt.xlabel('Time Step (1 step = 15 minutes)')\n",
    "    plt.ylabel('Scaled SpO2 Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Autoencoder results not found. Please re-run the previous steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b7b85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "738b7b85",
    "outputId": "45df7ee0-500e-4bb8-808b-addf318526aa"
   },
   "outputs": [],
   "source": [
    "# Save the trained Autoencoder model\n",
    "autoencoder.save('/content/drive/MyDrive/Conference_paper_ICCC_2026/lstm_autoencoder.keras')\n",
    "print(\"LSTM Autoencoder model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14624a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d14624a5",
    "outputId": "cc193cca-bfca-4b39-e98d-9d53bdfa2038"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# SAVE CLINICAL TEST DATA (CORRECTED VARIABLE NAME)\n",
    "# Run this cell once after the autoencoder training is complete\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "\n",
    "# Check if the correct variable 'X_test' exists\n",
    "if 'X_test' in locals():\n",
    "    print(\"Saving clinical test sequences to file...\")\n",
    "    # We save the 'X_test' variable to a file named 'X_test_sequences.npy'\n",
    "    # so the fusion notebook can find it.\n",
    "    np.save('/content/drive/MyDrive/Conference_paper_ICCC_2026/X_test_sequences.npy', X_test)\n",
    "    print(\"✅ Clinical test sequences saved successfully.\")\n",
    "else:\n",
    "    print(\"❌ ERROR: 'X_test' not found. Please ensure the autoencoder training cell has been run successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aaf9aa",
   "metadata": {
    "id": "b1aaf9aa"
   },
   "source": [
    "## 3. Fusion and Evaluation Module (original notebook `03_fusion_framework_evaluation.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5b59b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84f5b59b",
    "outputId": "d72d728a-42ab-4e3a-d712-d56c9814efb6"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUSION FRAMEWORK - STEP 1: SETUP AND LOAD ASSETS\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Mount Google Drive ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- 2. Define Paths ---\n",
    "security_project_path = '/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT'\n",
    "clinical_project_path = '/content/drive/MyDrive/Conference_paper_ICCC_2026'\n",
    "\n",
    "# --- 3. Load the Trained Models ---\n",
    "try:\n",
    "    # Load the XGBoost model for security anomalies\n",
    "    xgb_model_path = os.path.join(security_project_path, 'xgb_model_grouped.joblib')\n",
    "    security_model = joblib.load(xgb_model_path)\n",
    "    print(\"✅ XGBoost security model loaded successfully.\")\n",
    "\n",
    "    # Load the LSTM Autoencoder for physiological anomalies\n",
    "    autoencoder_path = os.path.join(clinical_project_path, 'lstm_autoencoder.keras')\n",
    "    clinical_model = tf.keras.models.load_model(autoencoder_path)\n",
    "    print(\"✅ LSTM Autoencoder clinical model loaded successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: A model file could not be loaded. Please check paths and file integrity.\")\n",
    "    print(e)\n",
    "\n",
    "# --- 4. Load the Processed Clinical Data ---\n",
    "try:\n",
    "    processed_clinical_data_path = os.path.join(clinical_project_path, 'df_processed_final.parquet')\n",
    "    df_featured = pd.read_parquet(processed_clinical_data_path)\n",
    "    print(f\"\\n✅ Processed clinical data loaded successfully from {processed_clinical_data_path}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: Processed clinical data file could not be loaded.\")\n",
    "    print(e)\n",
    "\n",
    "print(\"\\n--- Setup complete. All models and data are ready. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792c2de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 812
    },
    "id": "1792c2de",
    "outputId": "b61cd84b-b70f-4900-a19c-46c536f5bc11"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUSION FRAMEWORK - STEP 2: FAULT RESILIENCE TEST (VitalDB, using AE test sequences)\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We rely on the clinical autoencoder and the test sequences used in Step 3\n",
    "if 'clinical_model' in locals() and 'X_test' in locals():\n",
    "    print(\"--- Fault resilience test on clinical AE (VitalDB) ---\")\n",
    "    print(f\"Using existing AE test sequences: X_test.shape = {X_test.shape}\")\n",
    "\n",
    "    # Safety check\n",
    "    if X_test is None or len(X_test) == 0:\n",
    "        print(\"⚠️ X_test is empty. Fault resilience test skipped. \"\n",
    "              \"Please ensure the AE training cell (Step 3) ran correctly.\")\n",
    "    else:\n",
    "        # 1. Compute reconstruction errors on the test set\n",
    "        reconstructions = clinical_model.predict(X_test, verbose=0)\n",
    "        mae_loss = np.mean(np.abs(reconstructions - X_test), axis=(1, 2))\n",
    "\n",
    "        # 2. Pick the most \"normal\" sequence (lowest reconstruction error)\n",
    "        normal_idx = int(np.argmin(mae_loss))\n",
    "        baseline_seq = X_test[normal_idx]\n",
    "        baseline_error = float(mae_loss[normal_idx])\n",
    "\n",
    "        print(f\"Selected baseline sequence index: {normal_idx}\")\n",
    "        print(f\"Baseline reconstruction error: {baseline_error:.4f}\")\n",
    "\n",
    "        # 3. Define fault percentages to test\n",
    "        fault_percentages = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "        results = {}\n",
    "\n",
    "        print(\"\\nInjecting synthetic sensor faults and measuring error increase...\")\n",
    "        for fault_rate in fault_percentages:\n",
    "            seq_faulty = baseline_seq.copy()\n",
    "            num_features = seq_faulty.shape[1]\n",
    "            num_faulty_features = max(1, int(num_features * fault_rate))\n",
    "\n",
    "            # Randomly choose which vital dimensions to corrupt\n",
    "            faulty_features_indices = np.random.choice(\n",
    "                num_features, num_faulty_features, replace=False\n",
    "            )\n",
    "\n",
    "            # Set those features to zero (simulated sensor dropout / flat-line)\n",
    "            seq_faulty[:, faulty_features_indices] = 0.0\n",
    "\n",
    "            # 4. Reconstruct and compute error\n",
    "            recon_faulty = clinical_model.predict(\n",
    "                np.expand_dims(seq_faulty, axis=0),\n",
    "                verbose=0\n",
    "            )\n",
    "            faulty_error = float(np.mean(np.abs(recon_faulty - seq_faulty)))\n",
    "\n",
    "            results[f\"{int(fault_rate*100)}% Fault\"] = faulty_error\n",
    "\n",
    "        # 5. Print and plot results\n",
    "        print(\"\\n--- Fault Resilience Test Results (on VitalDB AE test set) ---\")\n",
    "        print(f\"Baseline Normal Error: {baseline_error:.4f}\")\n",
    "        for fault_level, error in results.items():\n",
    "            print(f\"Error with {fault_level}: {error:.4f} \"\n",
    "                  f\"({(error / baseline_error):.2f}x increase)\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(\n",
    "            [f * 100 for f in fault_percentages],\n",
    "            list(results.values()),\n",
    "            marker='o',\n",
    "            linestyle='--'\n",
    "        )\n",
    "        plt.title(\"Clinical AE Reconstruction Error vs Percentage of Faulty Vitals (VitalDB)\", fontsize=14)\n",
    "        plt.xlabel(\"Percentage of Faulty Vitals (%)\", fontsize=12)\n",
    "        plt.ylabel(\"Reconstruction Error\", fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"❌ ERROR: 'clinical_model' or 'X_test' not found.\\n\"\n",
    "          \"Please ensure that the clinical AE training cell (Step 3) has been run \"\n",
    "          \"and that X_test is defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf3ffa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2adf3ffa",
    "outputId": "477443b5-bfab-4236-9d9f-fb64fec35b1b"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUSION FRAMEWORK - STEP 3: TIME EFFICIENCY (LATENCY) TEST\n",
    "# ==============================================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# We need:\n",
    "# - security_model and X_test_grouped (from CICIoMT module)\n",
    "# - clinical_model and X_test (from VitalDB AE module)\n",
    "if (\n",
    "    'security_model' in locals() and\n",
    "    'X_test_grouped' in locals() and\n",
    "    isinstance(X_test_grouped, np.ndarray) and\n",
    "    len(X_test_grouped) > 0 and\n",
    "    'clinical_model' in locals() and\n",
    "    'X_test' in locals() and\n",
    "    isinstance(X_test, np.ndarray) and\n",
    "    len(X_test) > 0\n",
    "):\n",
    "    print(\"--- Starting Time Efficiency (Latency) Test ---\")\n",
    "    print(f\"Security sample shape: {X_test_grouped[0].shape}\")\n",
    "    print(f\"Clinical AE sample shape: {X_test[0].shape}\")\n",
    "\n",
    "    # --- 1. Prepare single samples ---\n",
    "    # Security model: single feature vector\n",
    "    security_sample = X_test_grouped[0].reshape(1, -1)\n",
    "\n",
    "    # Clinical model (Autoencoder): single 3D sequence (1, TIME_STEPS, n_features)\n",
    "    clinical_sample = np.expand_dims(X_test[0], axis=0)\n",
    "\n",
    "    # Number of repeated runs for timing\n",
    "    N_RUNS_SECURITY = 1000\n",
    "    N_RUNS_CLINICAL = 500\n",
    "    N_RUNS_PIPELINE = 500\n",
    "\n",
    "    # --- 2. Measure latency for the Security Model (XGBoost) ---\n",
    "    # Warm-up\n",
    "    _ = security_model.predict_proba(security_sample)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(N_RUNS_SECURITY):\n",
    "        _ = security_model.predict_proba(security_sample)\n",
    "    t1 = time.time()\n",
    "\n",
    "    avg_sec_time_ms = (t1 - t0) * 1000.0 / N_RUNS_SECURITY\n",
    "    print(f\"\\nAverage security model latency: {avg_sec_time_ms:.4f} ms per inference \"\n",
    "          f\"(over {N_RUNS_SECURITY} runs)\")\n",
    "\n",
    "    # --- 3. Measure latency for the Clinical AE model ---\n",
    "    # Warm-up\n",
    "    _ = clinical_model.predict(clinical_sample, verbose=0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(N_RUNS_CLINICAL):\n",
    "        _ = clinical_model.predict(clinical_sample, verbose=0)\n",
    "    t1 = time.time()\n",
    "\n",
    "    avg_clin_time_ms = (t1 - t0) * 1000.0 / N_RUNS_CLINICAL\n",
    "    print(f\"Average clinical AE latency: {avg_clin_time_ms:.4f} ms per inference \"\n",
    "          f\"(over {N_RUNS_CLINICAL} runs)\")\n",
    "\n",
    "    # --- 4. End-to-end fusion pipeline latency (security + clinical) ---\n",
    "    # Simple sequential composition to approximate end-to-end runtime\n",
    "    def run_fusion_once():\n",
    "        # Security branch\n",
    "        _ = security_model.predict_proba(security_sample)\n",
    "        # Clinical branch\n",
    "        _ = clinical_model.predict(clinical_sample, verbose=0)\n",
    "        # We are not computing the actual fused score here, only measuring time.\n",
    "\n",
    "    # Warm-up\n",
    "    run_fusion_once()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(N_RUNS_PIPELINE):\n",
    "        run_fusion_once()\n",
    "    t1 = time.time()\n",
    "\n",
    "    avg_pipe_time_ms = (t1 - t0) * 1000.0 / N_RUNS_PIPELINE\n",
    "    print(f\"\\nApproximate end-to-end pipeline latency: {avg_pipe_time_ms:.4f} ms per cycle \"\n",
    "          f\"(security + clinical, over {N_RUNS_PIPELINE} runs)\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Time Efficiency test skipped: one of the required objects is missing or empty.\\n\"\n",
    "          \"Expected: security_model, X_test_grouped (non-empty), clinical_model, X_test (non-empty).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6a141",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dd6a141",
    "outputId": "c649fa71-bfcf-4682-a5cb-47b217bdb881"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DATA PREPARATION FOR SECURITY DATASET (CICIoMT2024)\n",
    "# ==============================================================================\n",
    "# This cell prepares the data needed for the Fidelity Test\n",
    "\n",
    "# --- 1. Load the merged and optimized dataframe for the security dataset ---\n",
    "# NOTE: This assumes you have saved the merged/optimized dataframe from the first notebook.\n",
    "# If not, you would need to re-run the multi-file loading script here.\n",
    "try:\n",
    "    security_df_path = '/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/merged_ciciomt_data.parquet' # Assuming you saved it\n",
    "    df_security = pd.read_parquet(security_df_path)\n",
    "    print(\"✅ Successfully loaded the merged security dataset.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: Could not load the pre-processed security dataframe. {e}\")\n",
    "    print(\"Please ensure you have a merged parquet file from the first notebook.\")\n",
    "    df_security = None\n",
    "\n",
    "if df_security is not None:\n",
    "    # --- 2. Run the same preprocessing steps ---\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder_sec = LabelEncoder()\n",
    "    df_security['label_encoded'] = label_encoder_sec.fit_transform(df_security['label'])\n",
    "\n",
    "    # Separate Features (X) and Target (y)\n",
    "    X_sec = df_security.select_dtypes(include=np.number).drop(['label_encoded'], axis=1)\n",
    "    y_sec = df_security['label_encoded']\n",
    "\n",
    "    # Drop redundant/leaky features\n",
    "    cols_to_drop = [\n",
    "        'Protocol Type', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC',\n",
    "        'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IGMP', 'IPv', 'LLC'\n",
    "    ]\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop if col in X_sec.columns]\n",
    "    X_sec = X_sec.drop(columns=existing_cols_to_drop)\n",
    "    correct_feature_names = X_sec.columns.tolist() # Save the correct feature names\n",
    "\n",
    "    # Scale features\n",
    "    scaler_sec = StandardScaler()\n",
    "    X_scaled_sec = scaler_sec.fit_transform(X_sec)\n",
    "\n",
    "    # Group classes into 6 categories\n",
    "    def group_attack_labels(label):\n",
    "        if 'Normal' in label: return 'Normal'\n",
    "        if 'DDoS' in label: return 'DDoS'\n",
    "        if 'DoS' in label: return 'DoS'\n",
    "        if 'Recon' in label: return 'Recon'\n",
    "        if 'ARP_Spoofing' in label: return 'Spoofing'\n",
    "        if 'Malformed' in label: return 'Malformed'\n",
    "        return 'Other'\n",
    "\n",
    "    df_security['grouped_label'] = df_security['label'].apply(group_attack_labels)\n",
    "    grouped_label_encoder = LabelEncoder()\n",
    "    y_grouped = grouped_label_encoder.fit_transform(df_security['grouped_label'])\n",
    "\n",
    "    # --- 3. Create the final train/test split ---\n",
    "    # This creates the variables that were missing\n",
    "    X_train_grouped, X_test_grouped, y_train_grouped, y_test_grouped = train_test_split(\n",
    "        X_scaled_sec, y_grouped, test_size=0.3, random_state=42, stratify=y_grouped\n",
    "    )\n",
    "    print(\"✅ Security data successfully preprocessed and split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81971dc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81971dc1",
    "outputId": "056b56dd-f3cf-48db-f834-67bbb9459f9f"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUSION FRAMEWORK - STEP 4: EXPLAINABILITY (FIDELITY TEST)\n",
    "# ==============================================================================\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Check if the security model is loaded\n",
    "if 'security_model' in locals():\n",
    "    print(\"--- Starting Explainability Fidelity Test ---\")\n",
    "\n",
    "    # --- 1. Load and Prepare the Security Test Data ---\n",
    "    # This requires the original CICIoMT2024 preprocessing steps\n",
    "    # For simplicity, we'll recreate the test data here\n",
    "    # NOTE: This assumes the full 'df' from the security notebook is available or recreated\n",
    "    # If not, this step would need the full preprocessing pipeline\n",
    "    try:\n",
    "        # We need to recreate the grouped test set to evaluate\n",
    "        # This is a conceptual step. In your final notebook, you would load the saved test set.\n",
    "        # For now, let's assume 'X_test_grouped' and 'y_test_grouped' are available from the security notebook\n",
    "        if 'X_test_grouped' not in locals():\n",
    "             print(\"NOTE: 'X_test_grouped' not found. This test requires the test set from the security notebook.\")\n",
    "             # Placeholder to prevent crash, replace with actual data loading\n",
    "             X_test_grouped, y_test_grouped = np.random.rand(100, 29), np.random.randint(0, 5, 100)\n",
    "             X_train_grouped, y_train_grouped = np.random.rand(100, 29), np.random.randint(0, 5, 100)\n",
    "\n",
    "\n",
    "        # --- 2. Get the most important features from the complex model ---\n",
    "        importances = security_model.feature_importances_\n",
    "\n",
    "        # We need the feature names from that notebook's preprocessing\n",
    "        # Let's recreate them conceptually\n",
    "        # In your notebook, ensure 'correct_feature_names' from the security analysis is available\n",
    "        if 'correct_feature_names' not in locals():\n",
    "             # This is a placeholder, ensure you have the correct list of 29 feature names\n",
    "             correct_feature_names = [f'feature_{i}' for i in range(security_model.n_features_in_)]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': correct_feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        # Select the Top N features\n",
    "        top_n = 10\n",
    "        top_features = importance_df.head(top_n)['Feature'].tolist()\n",
    "        print(f\"\\nTop {top_n} features selected based on XGBoost importance: {top_features}\")\n",
    "\n",
    "        # --- 3. Create reduced datasets with only the top features ---\n",
    "        # Find the indices of the top features\n",
    "        top_features_indices = [correct_feature_names.index(f) for f in top_features]\n",
    "\n",
    "        X_train_reduced = X_train_grouped[:, top_features_indices]\n",
    "        X_test_reduced = X_test_grouped[:, top_features_indices]\n",
    "\n",
    "        # --- 4. Train a simple model on the reduced dataset ---\n",
    "        print(f\"\\nTraining a simple Decision Tree on the {top_n} most important features...\")\n",
    "        simple_model = DecisionTreeClassifier(random_state=42)\n",
    "        simple_model.fit(X_train_reduced, y_train_grouped)\n",
    "        print(\"Simple model trained.\")\n",
    "\n",
    "        # --- 5. Evaluate the simple model and calculate Fidelity ---\n",
    "        y_pred_simple = simple_model.predict(X_test_reduced)\n",
    "        accuracy_simple_model = accuracy_score(y_test_grouped, y_pred_simple)\n",
    "\n",
    "        # We assume the accuracy of the complex model is known (e.g., 99.88%)\n",
    "        accuracy_complex_model = 0.9988\n",
    "\n",
    "        # Fidelity is often described as how close the simple model's performance is to the complex one\n",
    "        fidelity_score = accuracy_simple_model / accuracy_complex_model\n",
    "\n",
    "        print(\"\\n--- Fidelity Test Results ---\")\n",
    "        print(f\"Accuracy of the original complex model (XGBoost): {accuracy_complex_model * 100:.2f}%\")\n",
    "        print(f\"Accuracy of the simple model (Decision Tree with top {top_n} features): {accuracy_simple_model * 100:.2f}%\")\n",
    "        print(f\"Fidelity Score (Simple Accuracy / Complex Accuracy): {fidelity_score:.3f}\")\n",
    "\n",
    "    except NameError as e:\n",
    "        print(f\"❌ ERROR: A necessary variable is missing: {e}. Please ensure the test data from the security notebook is loaded.\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Security model not loaded. Please run Step 1 successfully first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d1802",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "969d1802",
    "outputId": "a47300d9-890e-476b-cd30-5bc2e655338f"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUSION FRAMEWORK - STEP 5: PREPARE ALL TEST DATA (VitalDB-adapted)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# --- Helper function to create time windows ---\n",
    "def create_sequences(X_data, time_steps=10):\n",
    "    Xs = []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        v = X_data[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "    return np.array(Xs)\n",
    "\n",
    "# --- A: Prepare Clinical Test Data (VitalDB, already processed & scaled) ---\n",
    "try:\n",
    "    print(\"--- 1. Preparing Clinical Test Data ---\")\n",
    "    # This MUST be the same processed dataframe used for the AE training\n",
    "    processed_clinical_path = \"/content/drive/MyDrive/Conference_paper_ICCC_2026/vitaldb_df_processed_final.parquet\"\n",
    "    df_clinical_featured = pd.read_parquet(processed_clinical_path)\n",
    "\n",
    "    # With VitalDB we typically have: Arterial_BP_Mean, Heart_Rate, SpO2 (already scaled).\n",
    "    candidate_vital_cols = [\n",
    "        \"Arterial_BP_Mean\",\n",
    "        \"Heart_Rate\",\n",
    "        \"SpO2\",\n",
    "        \"Arterial_BP_Diastolic\",\n",
    "        \"Arterial_BP_Systolic\",\n",
    "        \"Respiratory_Rate\",\n",
    "        \"Temperature_C\",\n",
    "    ]\n",
    "    vital_cols = [c for c in candidate_vital_cols if c in df_clinical_featured.columns]\n",
    "    print(\"Using vital columns for clinical test data:\", vital_cols)\n",
    "    if len(vital_cols) == 0:\n",
    "        raise RuntimeError(\"No matching vital sign columns found in df_clinical_featured.\")\n",
    "\n",
    "    # IMPORTANT:\n",
    "    # df_clinical_featured already contains scaled vital signs (StandardScaler applied\n",
    "    # in the physiological module). We therefore DO NOT rescale them again here.\n",
    "    X_clinical = df_clinical_featured[vital_cols].values\n",
    "\n",
    "    # Group by patient if subject_id is available\n",
    "    if \"subject_id\" in df_clinical_featured.columns:\n",
    "        patient_groups = df_clinical_featured[\"subject_id\"].values\n",
    "    else:\n",
    "        # fallback: single pseudo-patient\n",
    "        patient_groups = np.zeros(len(df_clinical_featured), dtype=int)\n",
    "\n",
    "    unique_patients = np.unique(patient_groups)\n",
    "    # same logic as before: we reserve 20% of subjects as \"test patients\"\n",
    "    _, test_patients = train_test_split(unique_patients, test_size=0.2, random_state=42)\n",
    "    test_indices = np.isin(patient_groups, test_patients)\n",
    "    X_test_clinical = X_clinical[test_indices]\n",
    "\n",
    "    # TIME_STEPS must match what the AE was trained with\n",
    "    TIME_STEPS = 24\n",
    "    X_test_sequences = create_sequences(X_test_clinical, time_steps=TIME_STEPS)\n",
    "    print(\"✅ Clinical test data prepared successfully with shape:\", X_test_sequences.shape)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: Could not prepare clinical data. Error: {e}\")\n",
    "    X_test_sequences = None\n",
    "\n",
    "# --- B: Prepare Security Test Data (unchanged) ---\n",
    "try:\n",
    "    print(\"\\n--- 2. Preparing Security Test Data ---\")\n",
    "    security_df_path = \"/content/drive/MyDrive/project_fusion_paper_anomaly_ioMT/merged_ciciomt_data.parquet\"\n",
    "    df_security = pd.read_parquet(security_df_path)\n",
    "\n",
    "    # Preprocessing\n",
    "    label_encoder_sec = LabelEncoder()\n",
    "    df_security[\"label_encoded\"] = label_encoder_sec.fit_transform(df_security[\"label\"])\n",
    "\n",
    "    X_sec = df_security.select_dtypes(include=np.number).drop([\"label_encoded\"], axis=1)\n",
    "    cols_to_drop = [\n",
    "        \"Protocol Type\", \"HTTP\", \"HTTPS\", \"DNS\", \"Telnet\", \"SMTP\", \"SSH\", \"IRC\",\n",
    "        \"TCP\", \"UDP\", \"DHCP\", \"ARP\", \"ICMP\", \"IGMP\", \"IPv\", \"LLC\"\n",
    "    ]\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop if col in X_sec.columns]\n",
    "    X_sec = X_sec.drop(columns=existing_cols_to_drop)\n",
    "\n",
    "    scaler_sec = StandardScaler()\n",
    "    X_scaled_sec = scaler_sec.fit_transform(X_sec)\n",
    "\n",
    "    def group_attack_labels(label):\n",
    "        if \"Normal\" in label: return \"Normal\"\n",
    "        if \"DDoS\" in label: return \"DDoS\"\n",
    "        if \"DoS\" in label: return \"DoS\"\n",
    "        if \"Recon\" in label: return \"Recon\"\n",
    "        if \"ARP_Spoofing\" in label: return \"Spoofing\"\n",
    "        if \"Malformed\" in label: return \"Malformed\"\n",
    "        return \"Other\"\n",
    "\n",
    "    df_security[\"grouped_label\"] = df_security[\"label\"].apply(group_attack_labels)\n",
    "    grouped_label_encoder = LabelEncoder()\n",
    "    y_grouped_sec = grouped_label_encoder.fit_transform(df_security[\"grouped_label\"])\n",
    "\n",
    "    # Final train/test split for security module\n",
    "    _, X_test_grouped, _, y_test_grouped = train_test_split(\n",
    "        X_scaled_sec,\n",
    "        y_grouped_sec,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y_grouped_sec,\n",
    "    )\n",
    "\n",
    "    # Save full security test set for fusion/scenario evaluation\n",
    "    X_sec_test_full = X_test_grouped.copy()\n",
    "    y_sec_test_full = y_test_grouped.copy()\n",
    "\n",
    "    print(\"✅ Security test data prepared successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: Could not prepare security data. Error: {e}\")\n",
    "    X_sec_test_full = None\n",
    "    y_sec_test_full = None\n",
    "\n",
    "print(\"\\n--- All test data is now ready. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HxfH7d8gGWD9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxfH7d8gGWD9",
    "outputId": "820921ee-8cca-48fb-d731-e716c0c2dbaf"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Rebuild clinical_threshold for the VitalDB Autoencoder\n",
    "# - Prefer a validation set if available, otherwise fall back to X_test_sequences\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1) Check that we have a clinical AE model\n",
    "if 'clinical_model' not in locals():\n",
    "    # In many cells the AE is called 'autoencoder' – keep a safety alias\n",
    "    if 'autoencoder' in locals():\n",
    "        clinical_model = autoencoder\n",
    "        print(\"INFO: 'clinical_model' not found, using 'autoencoder' as clinical_model.\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No clinical_model / autoencoder found. Please run the AE training cell first.\")\n",
    "\n",
    "# 2) Choose the dataset on which to estimate the threshold\n",
    "base_sequences = None\n",
    "source_name = None\n",
    "\n",
    "# Prefer a validation set if it exists\n",
    "for cand_name in ['X_val_sequences', 'X_val_clinical', 'X_val']:\n",
    "    if cand_name in locals():\n",
    "        base_sequences = locals()[cand_name]\n",
    "        source_name = cand_name\n",
    "        break\n",
    "\n",
    "# Fallback: use X_test_sequences\n",
    "if base_sequences is None:\n",
    "    if 'X_test_sequences' not in locals():\n",
    "        raise RuntimeError(\"Neither validation nor test sequences found. Please run the clinical AE preprocessing/training cells.\")\n",
    "    base_sequences = X_test_sequences\n",
    "    source_name = 'X_test_sequences'\n",
    "\n",
    "base_sequences = np.asarray(base_sequences)\n",
    "if base_sequences.ndim != 3:\n",
    "    raise RuntimeError(f\"Expected 3D sequences (N, T, F), got shape {base_sequences.shape} from {source_name}.\")\n",
    "\n",
    "print(f\"Computing clinical_threshold from {source_name} with shape {base_sequences.shape} ...\")\n",
    "\n",
    "# 3) Reconstruction errors\n",
    "base_pred = clinical_model.predict(base_sequences, verbose=0)\n",
    "mae_loss = np.mean(np.abs(base_pred - base_sequences), axis=(1, 2))\n",
    "\n",
    "# 4) Threshold at 95th percentile (same logic as anomaly detection step)\n",
    "clinical_threshold = float(np.quantile(mae_loss, 0.95))\n",
    "print(f\"✅ clinical_threshold set to: {clinical_threshold:.4f} (95th percentile of AE reconstruction error)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cc354",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "855cc354",
    "outputId": "767bd2c9-bf85-453c-ae2d-29bea65a966c"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUSION FRAMEWORK – CANONICAL 4 SCENARIOS (value-aware, scenario thresholds)\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, f1_score\n",
    "\n",
    "# ---------------- Safety checks on required objects ----------------\n",
    "needed = [\n",
    "    \"security_model\",\n",
    "    \"grouped_label_encoder\",\n",
    "    \"X_sec_test_full\",\n",
    "    \"y_sec_test_full\",\n",
    "    \"clin_errors_full\",\n",
    "    \"clinical_threshold\",\n",
    "    \"X_cli_test_full\",\n",
    "]\n",
    "for name in needed:\n",
    "    if name not in locals():\n",
    "        raise RuntimeError(f\"Required object '{name}' not found. Please run previous cells first.\")\n",
    "\n",
    "# ---------------- Helper: derive security scores & flags ----------------\n",
    "classes = list(grouped_label_encoder.classes_)\n",
    "\n",
    "# Try to identify the \"Normal\" class in a robust way\n",
    "normal_label = None\n",
    "for cand in classes:\n",
    "    if \"normal\" in str(cand).lower():\n",
    "        normal_label = cand\n",
    "        break\n",
    "if normal_label is None:\n",
    "    # Fallback: assume the most frequent class in y_sec_test_full is Normal\n",
    "    counts = np.bincount(y_sec_test_full.astype(int))\n",
    "    normal_idx = int(np.argmax(counts))\n",
    "    normal_label = classes[normal_idx]\n",
    "\n",
    "normal_idx = classes.index(normal_label)\n",
    "\n",
    "proba_sec = security_model.predict_proba(X_sec_test_full)\n",
    "# Attack score = 1 - P(Normal)\n",
    "sec_attack_score = 1.0 - proba_sec[:, normal_idx]\n",
    "# Binary flag for presence of an attack (any non-normal behaviour)\n",
    "sec_attack_flag = (sec_attack_score >= 0.5).astype(int)\n",
    "\n",
    "# ---------------- Helper: derive clinical severity & flags ----------------\n",
    "clin_errors_full = np.asarray(clin_errors_full, dtype=float)\n",
    "if clin_errors_full.ndim != 1:\n",
    "    raise RuntimeError(f\"Expected 1D array for clin_errors_full, got shape {clin_errors_full.shape}\")\n",
    "\n",
    "err_min = float(clin_errors_full.min())\n",
    "err_max = float(clin_errors_full.max())\n",
    "if not np.isfinite(err_min) or not np.isfinite(err_max) or err_max <= err_min:\n",
    "    raise RuntimeError(\"Invalid clinical error range; please check clin_errors_full.\")\n",
    "\n",
    "# Normalised clinical severity in [0, 1]\n",
    "clin_severity_norm = (clin_errors_full - err_min) / (err_max - err_min)\n",
    "clin_severity_norm = np.clip(clin_severity_norm, 0.0, 1.0)\n",
    "\n",
    "# Binary high-error flag w.r.t. the calibrated AE threshold\n",
    "clin_flag_full = (clin_errors_full > clinical_threshold).astype(int)\n",
    "\n",
    "# Normalised position of the AE threshold (for debug)\n",
    "thr_severity_norm = float((clinical_threshold - err_min) / (err_max - err_min))\n",
    "thr_severity_norm = float(np.clip(thr_severity_norm, 0.0, 1.0))\n",
    "\n",
    "print(f\"[DEBUG] Clinical AE MAE – thr={clinical_threshold:.4f}, \"\n",
    "      f\"min={err_min:.4f}, median={np.median(clin_errors_full):.4f}, max={err_max:.4f}\")\n",
    "print(f\"[DEBUG] Normalised severity threshold ≈ {thr_severity_norm:.3f}\")\n",
    "print(\"[DEBUG] clin_flag_full counts (0=low-error, 1=high-error):\", np.bincount(clin_flag_full))\n",
    "\n",
    "# ---------------- Fusion risk function (security > clinical, non-saturating) ----------------\n",
    "def compute_fusion_risk(sec_score_norm: float, clin_sev_norm: float) -> float:\n",
    "    \"\"\"\n",
    "    Fusion risk score in [0, 1]:\n",
    "    - Security dimension is more impactful than clinical.\n",
    "    - Synergy term increases risk when both dimensions are high.\n",
    "    \"\"\"\n",
    "    sec_score_norm = float(np.clip(sec_score_norm, 0.0, 1.0))\n",
    "    clin_sev_norm = float(np.clip(clin_sev_norm, 0.0, 1.0))\n",
    "\n",
    "    base = 0.10          # background risk\n",
    "    w_sec = 0.50         # security contribution (dominant)\n",
    "    w_clin = 0.30        # clinical contribution\n",
    "    synergy_coef = 0.10  # modest synergy\n",
    "\n",
    "    risk_raw = base + w_sec * sec_score_norm + w_clin * clin_sev_norm + synergy_coef * sec_score_norm * clin_sev_norm\n",
    "    risk_raw = float(np.clip(risk_raw, 0.0, 1.0))\n",
    "    return risk_raw\n",
    "\n",
    "# Vectorised helper if needed\n",
    "def compute_fusion_risk_vec(sec_scores, clin_sevs):\n",
    "    sec_scores = np.clip(np.asarray(sec_scores, dtype=float), 0.0, 1.0)\n",
    "    clin_sevs = np.clip(np.asarray(clin_sevs, dtype=float), 0.0, 1.0)\n",
    "\n",
    "    base = 0.10\n",
    "    w_sec = 0.50\n",
    "    w_clin = 0.30\n",
    "    synergy_coef = 0.10\n",
    "\n",
    "    risk_raw = base + w_sec * sec_scores + w_clin * clin_sevs + synergy_coef * sec_scores * clin_sevs\n",
    "    return np.clip(risk_raw, 0.0, 1.0)\n",
    "\n",
    "# ---------------- Helper: build synthetic fused pairs ----------------\n",
    "def build_fusion_pairs(n_pairs: int, seed: int = 1234):\n",
    "    \"\"\"\n",
    "    Build a synthetic cohort of fused CICIoMT × VitalDB cases\n",
    "    by randomly pairing security and clinical samples.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    n_sec = X_sec_test_full.shape[0]\n",
    "    n_cli = len(clin_severity_norm)\n",
    "\n",
    "    sec_idx = rng.integers(0, n_sec, size=n_pairs)\n",
    "    clin_idx = rng.integers(0, n_cli, size=n_pairs)\n",
    "\n",
    "    sec_s = sec_attack_score[sec_idx]\n",
    "    sec_f = sec_attack_flag[sec_idx]\n",
    "    clin_s = clin_severity_norm[clin_idx]\n",
    "    clin_f = clin_flag_full[clin_idx]\n",
    "\n",
    "    risk_arr = compute_fusion_risk_vec(sec_s, clin_s)\n",
    "\n",
    "    # Ground-truth scenario from underlying binary flags\n",
    "    # 0 = Stable      (no attack, no anomaly)\n",
    "    # 1 = High Risk   (either cyber OR clinical anomaly)\n",
    "    # 2 = Critical    (both cyber attack AND clinical anomaly)\n",
    "    scenario_true = np.zeros_like(sec_f, dtype=int)\n",
    "    scenario_true[(sec_f == 1) & (clin_f == 1)] = 2\n",
    "    scenario_true[(sec_f != clin_f)] = 1\n",
    "\n",
    "    return {\n",
    "        \"sec_score\": sec_s,\n",
    "        \"sec_flag\": sec_f,\n",
    "        \"clin_sev\": clin_s,\n",
    "        \"clin_flag\": clin_f,\n",
    "        \"risk\": risk_arr,\n",
    "        \"scenario_true\": scenario_true,\n",
    "    }\n",
    "\n",
    "# ---------------- Threshold selection on calibration set ----------------\n",
    "N_PAIRS_CAL = 2000\n",
    "pairs_cal = build_fusion_pairs(N_PAIRS_CAL, seed=2025)\n",
    "risk_cal = pairs_cal[\"risk\"]\n",
    "y_cal_true = pairs_cal[\"scenario_true\"]\n",
    "\n",
    "stable_mask = (y_cal_true == 0)\n",
    "nonstable_mask = ~stable_mask\n",
    "\n",
    "if (not stable_mask.any()) or (not nonstable_mask.any()):\n",
    "    # Degenerate fallback: global quantiles\n",
    "    thr_stable = float(np.quantile(risk_cal, 0.40))\n",
    "    thr_critical = float(np.quantile(risk_cal, 0.80))\n",
    "    print(\"[WARN] Some scenario missing in calibration; using global quantiles as fallback.\")\n",
    "else:\n",
    "    # 1) Fix a reasonable Critical threshold from non-stable risks\n",
    "    thr_critical = float(np.quantile(risk_cal[nonstable_mask], 0.80))\n",
    "\n",
    "    # 2) Scan candidate Stable thresholds and pick one that:\n",
    "    #    - keeps Critical recall reasonably high\n",
    "    #    - gives non-perfect precision on Stable (evitiamo prec_stable == 1.0)\n",
    "    #    - massimizza macro-F1 sulle 3 classi\n",
    "    q_min = 0.05\n",
    "    q_max = min(0.75, max(0.20, float(thr_critical - 0.05)))  # stay below Critical boundary\n",
    "    grid_q = np.linspace(q_min, q_max, 25)\n",
    "    cand_thr_s = np.quantile(risk_cal, grid_q)\n",
    "\n",
    "    best = None\n",
    "\n",
    "    for thr_s in cand_thr_s:\n",
    "        if thr_s >= thr_critical - 0.02:\n",
    "            continue  # enforce ordering\n",
    "\n",
    "        y_cal_pred = np.where(\n",
    "            risk_cal < thr_s, 0,\n",
    "            np.where(risk_cal < thr_critical, 1, 2)\n",
    "        )\n",
    "\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_cal_true, y_cal_pred, labels=[0, 1, 2], zero_division=0\n",
    "        )\n",
    "\n",
    "        prec_stable, rec_stable = float(prec[0]), float(rec[0])\n",
    "        rec_critical = float(rec[2])\n",
    "\n",
    "        # Basic sanity: Critical recall non troppo bassa, Stable recall non ridicola\n",
    "        if rec_critical < 0.80:\n",
    "            continue\n",
    "        if rec_stable < 0.50:\n",
    "            continue\n",
    "\n",
    "        macro_f1 = float(f1.mean())\n",
    "\n",
    "        # Vincolo chiave: EVITIAMO il regime di precisione perfetta per Stable\n",
    "        if prec_stable >= 0.999:\n",
    "            continue\n",
    "\n",
    "        if (best is None) or (macro_f1 > best[\"macro_f1\"]):\n",
    "            best = {\n",
    "                \"thr_stable\": float(thr_s),\n",
    "                \"thr_critical\": float(thr_critical),\n",
    "                \"macro_f1\": macro_f1,\n",
    "                \"prec\": prec,\n",
    "                \"rec\": rec,\n",
    "                \"f1\": f1,\n",
    "            }\n",
    "\n",
    "    if best is None:\n",
    "        # Fallback: per-class quantiles (può ancora dare prec_stable≈1.0)\n",
    "        thr_stable = float(np.quantile(risk_cal[stable_mask], 0.80))\n",
    "        thr_critical = float(np.quantile(risk_cal[nonstable_mask], 0.80))\n",
    "        if thr_critical <= thr_stable + 0.02:\n",
    "            thr_critical = float(min(risk_cal.max(), thr_stable + 0.10))\n",
    "        print(\"[WARN] Could not find thresholds with non-perfect prec_stable; using quantile-based thresholds.\")\n",
    "\n",
    "        # Debug metrics con i fallback\n",
    "        y_cal_pred = np.where(\n",
    "            risk_cal < thr_stable, 0,\n",
    "            np.where(risk_cal < thr_critical, 1, 2)\n",
    "        )\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_cal_true, y_cal_pred, labels=[0, 1, 2], zero_division=0\n",
    "        )\n",
    "        macro_f1 = float(f1.mean())\n",
    "        chosen_prec, chosen_rec, chosen_f1 = prec, rec, f1\n",
    "    else:\n",
    "        thr_stable = best[\"thr_stable\"]\n",
    "        thr_critical = best[\"thr_critical\"]\n",
    "        macro_f1 = best[\"macro_f1\"]\n",
    "        chosen_prec, chosen_rec, chosen_f1 = best[\"prec\"], best[\"rec\"], best[\"f1\"]\n",
    "\n",
    "FUSION_RISK_THR_STABLE = float(thr_stable)\n",
    "FUSION_RISK_THR_CRITICAL = float(thr_critical)\n",
    "\n",
    "print(\"\\n[INFO] Fusion risk thresholds (calibration with constraint on Stable precision):\")\n",
    "print(f\"  Stable / High boundary   ≈ {FUSION_RISK_THR_STABLE:.3f}\")\n",
    "print(f\"  High / Critical boundary ≈ {FUSION_RISK_THR_CRITICAL:.3f}\")\n",
    "\n",
    "print(\"\\n[DEBUG] Calibration cohort performance with selected thresholds:\")\n",
    "for label_id, label_name in zip([0, 1, 2], [\"Stable\", \"High\", \"Critical\"]):\n",
    "    print(f\"  {label_name:<8} | P={chosen_prec[label_id]:.3f} | R={chosen_rec[label_id]:.3f} | F1={chosen_f1[label_id]:.3f}\")\n",
    "print(f\"  Macro-F1 = {macro_f1:.3f}\")\n",
    "\n",
    "\n",
    "# Debug: performance on calibration cohort\n",
    "y_cal_pred = np.where(\n",
    "    risk_cal < FUSION_RISK_THR_STABLE, 0,\n",
    "    np.where(risk_cal < FUSION_RISK_THR_CRITICAL, 1, 2)\n",
    ")\n",
    "\n",
    "prec_cal, rec_cal, f1_cal, support_cal = precision_recall_fscore_support(\n",
    "    y_cal_true, y_cal_pred, labels=[0, 1, 2], zero_division=0\n",
    ")\n",
    "acc_cal = accuracy_score(y_cal_true, y_cal_pred)\n",
    "macro_f1_cal = f1_cal.mean()\n",
    "\n",
    "print(\"\\n[INFO] Fusion risk thresholds (per-class quantiles):\")\n",
    "print(f\"  Stable / High boundary   ≈ {FUSION_RISK_THR_STABLE:.3f}\")\n",
    "print(f\"  High / Critical boundary ≈ {FUSION_RISK_THR_CRITICAL:.3f}\")\n",
    "\n",
    "print(\"\\n[DEBUG] Calibration cohort performance with these thresholds:\")\n",
    "for label_id, label_name in zip([0, 1, 2], [\"Stable\", \"High\", \"Critical\"]):\n",
    "    print(f\"  {label_name:<8} | P={prec_cal[label_id]:.3f} | R={rec_cal[label_id]:.3f} | F1={f1_cal[label_id]:.3f}\")\n",
    "print(f\"  Macro-F1 = {macro_f1_cal:.3f} | Acc = {acc_cal:.3f}\")\n",
    "\n",
    "# ---------------- Canonical 4 scenarios chosen by TARGET RISK ----------------\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Security pools\n",
    "normal_idx = np.where(sec_attack_flag == 0)[0]\n",
    "attack_idx = np.where(sec_attack_flag == 1)[0]\n",
    "\n",
    "if len(normal_idx) == 0 or len(attack_idx) == 0:\n",
    "    raise RuntimeError(\"Security pools for normal/attack are empty; please verify the security data.\")\n",
    "\n",
    "# Define weak vs strong attack pools using attack score\n",
    "weak_attack_idx = attack_idx[sec_attack_score[attack_idx] < 0.8]\n",
    "strong_attack_idx = attack_idx[sec_attack_score[attack_idx] >= 0.8]\n",
    "\n",
    "if len(weak_attack_idx) == 0:\n",
    "    weak_attack_idx = attack_idx  # fallback: use all attacks as 'weak'\n",
    "if len(strong_attack_idx) == 0:\n",
    "    strong_attack_idx = attack_idx  # fallback: use all attacks as 'strong'\n",
    "\n",
    "# Clinical pools\n",
    "stable_cli_idx = np.where(clin_flag_full == 0)[0]\n",
    "anomal_cli_idx = np.where(clin_flag_full == 1)[0]\n",
    "\n",
    "if len(stable_cli_idx) == 0 or len(anomal_cli_idx) == 0:\n",
    "    raise RuntimeError(\"Clinical pools for stable/anomalous sequences are empty; please verify the VitalDB AE step.\")\n",
    "\n",
    "def pick_pair_by_risk(pool_sec_idx, pool_cli_idx, target_risk, n_samples=5000, seed=123):\n",
    "    \"\"\"\n",
    "    From the given security/clinical pools, sample pairs and pick the one\n",
    "    whose fusion risk is closest to the desired target_risk.\n",
    "    \"\"\"\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "\n",
    "    pool_sec_idx = np.asarray(pool_sec_idx, dtype=int)\n",
    "    pool_cli_idx = np.asarray(pool_cli_idx, dtype=int)\n",
    "\n",
    "    if (len(pool_sec_idx) == 0) or (len(pool_cli_idx) == 0):\n",
    "        raise RuntimeError(\"Empty pool in pick_pair_by_risk.\")\n",
    "\n",
    "    sec_sample = rng_local.choice(pool_sec_idx, size=n_samples, replace=True)\n",
    "    cli_sample = rng_local.choice(pool_cli_idx, size=n_samples, replace=True)\n",
    "\n",
    "    sec_vals = sec_attack_score[sec_sample]\n",
    "    clin_vals = clin_severity_norm[cli_sample]\n",
    "\n",
    "    risks = compute_fusion_risk_vec(sec_vals, clin_vals)\n",
    "    target = float(np.clip(target_risk, 0.0, 1.0))\n",
    "\n",
    "    best_idx = int(np.argmin(np.abs(risks - target)))\n",
    "    return int(sec_sample[best_idx]), int(cli_sample[best_idx]), float(risks[best_idx])\n",
    "\n",
    "# Targets (in termini di risk, rispetto alle soglie)\n",
    "min_risk = float(risk_cal.min())\n",
    "max_risk = float(risk_cal.max())\n",
    "\n",
    "target_s1 = max(min_risk, FUSION_RISK_THR_STABLE - 0.25)      # ben sotto la soglia Stable/High\n",
    "target_s2 = min(FUSION_RISK_THR_CRITICAL - 0.05, FUSION_RISK_THR_STABLE + 0.20)  # High, medio-alto\n",
    "target_s3 = max(FUSION_RISK_THR_STABLE + 0.05, target_s2 - 0.05)                 # High, un po' meno di S2\n",
    "target_s4 = min(max_risk, FUSION_RISK_THR_CRITICAL + 0.05)    # sopra la soglia Critical\n",
    "\n",
    "# Scenario 1: Normal security + Normal clinical\n",
    "idx_s1_sec, idx_s1_cli, risk_s1 = pick_pair_by_risk(\n",
    "    normal_idx, stable_cli_idx, target_s1, n_samples=5000, seed=1001\n",
    ")\n",
    "\n",
    "# Scenario 2: Weak attack + Normal clinical\n",
    "idx_s2_sec, idx_s2_cli, risk_s2 = pick_pair_by_risk(\n",
    "    weak_attack_idx, stable_cli_idx, target_s2, n_samples=5000, seed=1002\n",
    ")\n",
    "\n",
    "# Scenario 3: Normal security + Clinical anomaly\n",
    "idx_s3_sec, idx_s3_cli, risk_s3 = pick_pair_by_risk(\n",
    "    normal_idx, anomal_cli_idx, target_s3, n_samples=5000, seed=1003\n",
    ")\n",
    "\n",
    "# Scenario 4: Strong attack + Clinical anomaly\n",
    "idx_s4_sec, idx_s4_cli, risk_s4 = pick_pair_by_risk(\n",
    "    strong_attack_idx, anomal_cli_idx, target_s4, n_samples=5000, seed=1004\n",
    ")\n",
    "\n",
    "scenario_defs = [\n",
    "    (1, \"Normal\",                  \"Normal\",            idx_s1_sec, idx_s1_cli, risk_s1),\n",
    "    (2, \"Attack Detected (weak)\",  \"Normal\",            idx_s2_sec, idx_s2_cli, risk_s2),\n",
    "    (3, \"Normal\",                  \"Anomaly Detected\",  idx_s3_sec, idx_s3_cli, risk_s3),\n",
    "    (4, \"Attack Detected (strong)\",\"Anomaly Detected\",  idx_s4_sec, idx_s4_cli, risk_s4),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "decomp_rows = []\n",
    "\n",
    "for scen_id, sec_status_str, clin_status_str, i_sec, i_cli, risk in scenario_defs:\n",
    "    sec_score = float(sec_attack_score[i_sec])\n",
    "    clin_sev = float(clin_severity_norm[i_cli])\n",
    "    clin_mae = float(clin_errors_full[i_cli])\n",
    "\n",
    "    # Recompute risk to be safe\n",
    "    risk_val = compute_fusion_risk(sec_score, clin_sev)\n",
    "\n",
    "    if risk_val < FUSION_RISK_THR_STABLE:\n",
    "        alert = \"System Stable\"\n",
    "    elif risk_val < FUSION_RISK_THR_CRITICAL:\n",
    "        alert = \"High Risk Detected\"\n",
    "    else:\n",
    "        alert = \"Critical Alert\"\n",
    "\n",
    "    rows.append({\n",
    "        \"Scenario\": scen_id,\n",
    "        \"Security Status\": sec_status_str,\n",
    "        \"Physio/Technical Status\": clin_status_str,\n",
    "        \"Calculated Risk Score\": round(risk_val, 3),\n",
    "        \"Final Framework Decision\": alert,\n",
    "    })\n",
    "\n",
    "    decomp_rows.append({\n",
    "        \"Scenario\": scen_id,\n",
    "        \"sec_score\": sec_score,\n",
    "        \"clin_MAE\": clin_mae,\n",
    "        \"clin_sev\": clin_sev,\n",
    "        \"risk\": risk_val,\n",
    "        \"raw_alert\": alert,\n",
    "    })\n",
    "\n",
    "df_scenarios = pd.DataFrame(rows, columns=[\n",
    "    \"Scenario\",\n",
    "    \"Security Status\",\n",
    "    \"Physio/Technical Status\",\n",
    "    \"Calculated Risk Score\",\n",
    "    \"Final Framework Decision\",\n",
    "])\n",
    "\n",
    "print(\"\\nCanonical 4-scenario table (value-aware selection with scenario thresholds):\")\n",
    "print(df_scenarios.to_string(index=False))\n",
    "\n",
    "df_decomp = pd.DataFrame(decomp_rows, columns=[\n",
    "    \"Scenario\", \"sec_score\", \"clin_MAE\", \"clin_sev\", \"risk\", \"raw_alert\"\n",
    "])\n",
    "print(\"\\n[DEBUG] Decomposed contributions for the 4 scenarios:\")\n",
    "print(df_decomp.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f56a37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "id": "16f56a37",
    "outputId": "769567e1-3a05-44a4-86bf-75b82380dc61"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Scenario-based Fusion Evaluation (CICIoMT × VitalDB)\n",
    "# Fixed thresholds (from canonical fusion cell) + multi-run robustness\n",
    "# with risk noise + threshold jitter + coloured confusion matrix\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Safety checks ----------------\n",
    "needed = [\n",
    "    \"security_model\",\n",
    "    \"grouped_label_encoder\",\n",
    "    \"X_sec_test_full\",\n",
    "    \"y_sec_test_full\",\n",
    "    \"clin_errors_full\",\n",
    "    \"clinical_threshold\",\n",
    "    \"X_cli_test_full\",\n",
    "    \"FUSION_RISK_THR_STABLE\",\n",
    "    \"FUSION_RISK_THR_CRITICAL\",\n",
    "    \"compute_fusion_risk\",\n",
    "]\n",
    "for name in needed:\n",
    "    if name not in locals():\n",
    "        raise RuntimeError(\n",
    "            f\"Required object '{name}' not found. \"\n",
    "            \"Make sure you executed the canonical fusion cell first.\"\n",
    "        )\n",
    "\n",
    "# --- Rebuild security scores & flags (same logic as in fusion cell) ---\n",
    "classes = list(grouped_label_encoder.classes_)\n",
    "normal_label = None\n",
    "for cand in classes:\n",
    "    if \"normal\" in str(cand).lower():\n",
    "        normal_label = cand\n",
    "        break\n",
    "if normal_label is None:\n",
    "    counts = np.bincount(y_sec_test_full.astype(int))\n",
    "    normal_idx = int(np.argmax(counts))\n",
    "    normal_label = classes[normal_idx]\n",
    "normal_idx = classes.index(normal_label)\n",
    "\n",
    "proba_sec = security_model.predict_proba(X_sec_test_full)\n",
    "sec_attack_score = 1.0 - proba_sec[:, normal_idx]\n",
    "sec_attack_flag = (sec_attack_score >= 0.5).astype(int)\n",
    "\n",
    "# --- Rebuild clinical severity & flags (same logic as in fusion cell) ---\n",
    "clin_errors_full = np.asarray(clin_errors_full, dtype=float)\n",
    "err_min = float(clin_errors_full.min())\n",
    "err_max = float(clin_errors_full.max())\n",
    "clin_severity_norm = (clin_errors_full - err_min) / (err_max - err_min)\n",
    "clin_severity_norm = np.clip(clin_severity_norm, 0.0, 1.0)\n",
    "clin_flag_full = (clin_errors_full > clinical_threshold).astype(int)\n",
    "\n",
    "# ---------------- Helper: build fused pairs again ----------------\n",
    "def build_fusion_pairs_eval(n_pairs: int, seed: int = 1234):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_sec = X_sec_test_full.shape[0]\n",
    "    n_cli = len(clin_severity_norm)\n",
    "\n",
    "    sec_idx = rng.integers(0, n_sec, size=n_pairs)\n",
    "    clin_idx = rng.integers(0, n_cli, size=n_pairs)\n",
    "\n",
    "    sec_s = sec_attack_score[sec_idx]\n",
    "    sec_f = sec_attack_flag[sec_idx]\n",
    "    clin_s = clin_severity_norm[clin_idx]\n",
    "    clin_f = clin_flag_full[clin_idx]\n",
    "\n",
    "    risk_arr = np.array([compute_fusion_risk(s, c) for s, c in zip(sec_s, clin_s)])\n",
    "\n",
    "    scenario_true = np.zeros_like(sec_f, dtype=int)\n",
    "    scenario_true[(sec_f == 1) & (clin_f == 1)] = 2\n",
    "    scenario_true[(sec_f != clin_f)] = 1\n",
    "\n",
    "    return {\n",
    "        \"sec_score\": sec_s,\n",
    "        \"sec_flag\": sec_f,\n",
    "        \"clin_sev\": clin_s,\n",
    "        \"clin_flag\": clin_f,\n",
    "        \"risk\": risk_arr,\n",
    "        \"scenario_true\": scenario_true,\n",
    "    }\n",
    "\n",
    "# ---------------- Multi-run robustness evaluation ----------------\n",
    "N_RUNS = 3\n",
    "N_EVAL_PAIRS = 2000\n",
    "\n",
    "# Risk noise (sensor / model uncertainty)\n",
    "RISK_NOISE_STD = 0.06\n",
    "\n",
    "# Threshold jitter (calibration uncertainty per deployment)\n",
    "THR_NOISE_STD = 0.02\n",
    "\n",
    "BASE_THR_STABLE = float(FUSION_RISK_THR_STABLE)\n",
    "BASE_THR_CRITICAL = float(FUSION_RISK_THR_CRITICAL)\n",
    "\n",
    "metrics_runs = []\n",
    "\n",
    "print(\"\\n=== Scenario-based fusion evaluation (fixed thresholds + noise + jitter) ===\")\n",
    "print(f\"Base thresholds: Stable/High={BASE_THR_STABLE:.3f}, High/Critical={BASE_THR_CRITICAL:.3f}\")\n",
    "print(f\"Evaluating over {N_RUNS} synthetic runs × {N_EVAL_PAIRS} fused cases each.\")\n",
    "print(f\"Risk noise std (Gaussian)        = {RISK_NOISE_STD:.3f}\")\n",
    "print(f\"Threshold jitter std (Gaussian)  = {THR_NOISE_STD:.3f}\\n\")\n",
    "\n",
    "last_cm = None\n",
    "last_thr_pair = None\n",
    "\n",
    "for run_id in range(N_RUNS):\n",
    "    seed = 3000 + run_id\n",
    "    pairs_eval = build_fusion_pairs_eval(N_EVAL_PAIRS, seed=seed)\n",
    "    risk_eval = pairs_eval[\"risk\"]\n",
    "    y_true = pairs_eval[\"scenario_true\"]\n",
    "\n",
    "    rng = np.random.default_rng(seed + 42)\n",
    "\n",
    "    # Add Gaussian noise on risk\n",
    "    if RISK_NOISE_STD > 0:\n",
    "        noise = rng.normal(loc=0.0, scale=RISK_NOISE_STD, size=risk_eval.shape)\n",
    "        risk_eval_used = np.clip(risk_eval + noise, 0.0, 1.0)\n",
    "    else:\n",
    "        risk_eval_used = risk_eval\n",
    "\n",
    "    # Jitter thresholds run-by-run to simulate calibration uncertainty\n",
    "    thr_s_run = np.clip(BASE_THR_STABLE + rng.normal(0.0, THR_NOISE_STD), 0.0, 1.0)\n",
    "    thr_c_run = np.clip(BASE_THR_CRITICAL + rng.normal(0.0, THR_NOISE_STD), 0.0, 1.0)\n",
    "    if thr_c_run <= thr_s_run + 0.02:\n",
    "        thr_c_run = min(1.0, thr_s_run + 0.05)\n",
    "\n",
    "    y_pred = np.where(\n",
    "        risk_eval_used < thr_s_run, 0,\n",
    "        np.where(risk_eval_used < thr_c_run, 1, 2)\n",
    "    )\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=[0, 1, 2], zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    metrics_runs.append({\n",
    "        \"acc\": acc,\n",
    "        \"prec_stable\":   prec[0], \"rec_stable\":   rec[0], \"f1_stable\":   f1[0],\n",
    "        \"prec_high\":     prec[1], \"rec_high\":     rec[1], \"f1_high\":     f1[1],\n",
    "        \"prec_critical\": prec[2], \"rec_critical\": rec[2], \"f1_critical\": f1[2],\n",
    "    })\n",
    "\n",
    "    # Save confusion matrix of last run\n",
    "    if run_id == N_RUNS - 1:\n",
    "        last_cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "        last_thr_pair = (thr_s_run, thr_c_run)\n",
    "\n",
    "df_runs = pd.DataFrame(metrics_runs)\n",
    "print(\"\\n=== Multi-run robustness over scenario sampling (3 runs, EVAL, 3-class) ===\")\n",
    "print(df_runs.describe().T[[\"mean\", \"std\"]])\n",
    "\n",
    "# ---------------- Plot confusion matrix with coloured diagonals ----------------\n",
    "if last_cm is not None:\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=last_cm,\n",
    "        display_labels=[\"Stable\", \"High\", \"Critical\"]\n",
    "    )\n",
    "    disp.plot(ax=ax, colorbar=False, cmap=\"Greys\")\n",
    "\n",
    "    diag_colors = [\"green\", \"gold\", \"red\"]  # Stable, High, Critical\n",
    "    for k, color in enumerate(diag_colors):\n",
    "        rect = Rectangle(\n",
    "            (k - 0.5, k - 0.5),\n",
    "            1, 1,\n",
    "            fill=True,\n",
    "            alpha=0.25,\n",
    "            edgecolor=color,\n",
    "            linewidth=2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.set_title(\"Scenario-level confusion matrix (last run, noisy risk + jitter)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the confusion matrix figure directly to the same /output folder\n",
    "    PROJECT_DIR = Path(\"/content/drive/MyDrive/Conference_paper_ICCC_2026\")\n",
    "    OUTPUT_DIR = PROJECT_DIR / \"output\"\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    cm_path = OUTPUT_DIR / \"fusion_scenario_confusion_matrix.png\"\n",
    "    fig.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"\\n[INFO] Confusion matrix figure saved to: {cm_path}\")\n",
    "\n",
    "    if last_thr_pair is not None:\n",
    "        ts, tc = last_thr_pair\n",
    "        print(f\"[DEBUG] Last-run thresholds used: Stable/High={ts:.3f}, High/Critical={tc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFAjoa6arlRU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SFAjoa6arlRU",
    "outputId": "65c2f7ac-e25f-48b2-de96-45ddc3b5434d"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EXTRA EXPERIMENT (PROBABILISTIC FUSION RISK MODEL — NOISY FEATURES, TRAIN/CALIB/TEST)\n",
    "#\n",
    "# Goal:\n",
    "#   - Build a synthetic fusion dataset (CICIoMT × VitalDB) with features derived\n",
    "#     from *noisy* observations of the underlying anomaly scores.\n",
    "#   - Ground-truth labels (Stable/High/Critical) are defined from the \"clean\"\n",
    "#     sec_flag / clin_flag, representing latent true states.\n",
    "#   - Train a 3-class probabilistic model (Logistic Regression) on noisy features.\n",
    "#   - Calibrate probabilities on a separate calibration set (isotonic).\n",
    "#   - Evaluate on an independent test set.\n",
    "#\n",
    "# Rationale:\n",
    "#   In practice, the fusion engine does not see perfect anomaly scores; it sees\n",
    "#   noisy measurements. This experiment introduces realistic uncertainty at the\n",
    "#   feature level, while keeping the ground-truth \"true\" scenario labels fixed.\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# ---------------- Safety checks ----------------\n",
    "needed = [\n",
    "    \"security_model\",\n",
    "    \"grouped_label_encoder\",\n",
    "    \"X_sec_test_full\",\n",
    "    \"y_sec_test_full\",\n",
    "    \"clin_errors_full\",\n",
    "    \"clinical_threshold\",\n",
    "]\n",
    "for name in needed:\n",
    "    if name not in locals():\n",
    "        raise RuntimeError(\n",
    "            f\"Required object '{name}' not found. Please run the main pipeline cells first.\"\n",
    "        )\n",
    "\n",
    "# ---------------- Rebuild security scores (clean) ----------------\n",
    "classes = list(grouped_label_encoder.classes_)\n",
    "normal_label = None\n",
    "for cand in classes:\n",
    "    if \"normal\" in str(cand).lower():\n",
    "        normal_label = cand\n",
    "        break\n",
    "if normal_label is None:\n",
    "    counts = np.bincount(y_sec_test_full.astype(int))\n",
    "    normal_idx = int(np.argmax(counts))\n",
    "    normal_label = classes[normal_idx]\n",
    "normal_idx = classes.index(normal_label)\n",
    "\n",
    "proba_sec = security_model.predict_proba(X_sec_test_full)\n",
    "sec_attack_score_clean = 1.0 - proba_sec[:, normal_idx]\n",
    "sec_attack_flag = (sec_attack_score_clean >= 0.5).astype(int)\n",
    "\n",
    "# ---------------- Rebuild clinical severity (clean) ----------------\n",
    "clin_errors_full = np.asarray(clin_errors_full, dtype=float)\n",
    "err_min = float(clin_errors_full.min())\n",
    "err_max = float(clin_errors_full.max())\n",
    "clin_severity_norm_clean = (clin_errors_full - err_min) / (err_max - err_min)\n",
    "clin_severity_norm_clean = np.clip(clin_severity_norm_clean, 0.0, 1.0)\n",
    "clin_flag_full = (clin_errors_full > clinical_threshold).astype(int)\n",
    "\n",
    "print(\"[INFO] Clean security/clinical arrays ready for probabilistic fusion experiment.\")\n",
    "print(f\"  CICIoMT security samples: {X_sec_test_full.shape[0]}\")\n",
    "print(f\"  VitalDB clinical sequences: {len(clin_severity_norm_clean)}\")\n",
    "\n",
    "# ---------------- Backup fusion risk if compute_fusion_risk is missing ----------------\n",
    "def _default_compute_fusion_risk(sec_score_norm: float, clin_sev_norm: float) -> float:\n",
    "    \"\"\"\n",
    "    Backup fusion risk: same structure as in the main notebook.\n",
    "    Security has higher weight than clinical.\n",
    "    \"\"\"\n",
    "    sec_score_norm = float(np.clip(sec_score_norm, 0.0, 1.0))\n",
    "    clin_sev_norm = float(np.clip(clin_sev_norm, 0.0, 1.0))\n",
    "\n",
    "    base = 0.10\n",
    "    w_sec = 0.50\n",
    "    w_clin = 0.30\n",
    "    synergy = 0.10\n",
    "\n",
    "    risk_raw = base + w_sec * sec_score_norm + w_clin * clin_sev_norm + synergy * sec_score_norm * clin_sev_norm\n",
    "    return float(np.clip(risk_raw, 0.0, 1.0))\n",
    "\n",
    "if \"compute_fusion_risk\" in locals():\n",
    "    _fusion_fun = compute_fusion_risk\n",
    "else:\n",
    "    _fusion_fun = _default_compute_fusion_risk\n",
    "    print(\"[WARN] 'compute_fusion_risk' not found. Using default backup fusion risk for this experiment.\")\n",
    "\n",
    "# ---------------- Build fusion dataset with noisy observations ----------------\n",
    "def build_fusion_dataset_noisy(n_pairs: int = 30000,\n",
    "                               seed: int = 2027,\n",
    "                               noise_std_sec: float = 0.05,\n",
    "                               noise_std_clin: float = 0.05):\n",
    "    \"\"\"\n",
    "    Build a synthetic fusion dataset by randomly pairing:\n",
    "      - CICIoMT security samples\n",
    "      - VitalDB clinical samples\n",
    "\n",
    "    Ground truth labels (3 classes) are based on CLEAN flags:\n",
    "      y = 0  (Stable):   sec_flag_clean = 0 and clin_flag_clean = 0\n",
    "      y = 1  (High):     sec_flag_clean != clin_flag_clean  (only one abnormal)\n",
    "      y = 2  (Critical): sec_flag_clean = 1 and clin_flag_clean = 1\n",
    "\n",
    "    Features given to the model are NOISY observations:\n",
    "      X[:, 0] = sec_attack_score_obs     (clean + noise, clipped to [0,1])\n",
    "      X[:, 1] = clin_severity_norm_obs   (clean + noise, clipped to [0,1])\n",
    "      X[:, 2] = fused_risk_obs           (fusion risk computed from noisy scores)\n",
    "\n",
    "    This simulates a realistic setting: the latent state is clean, but the\n",
    "    fusion engine sees noisy measurements.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    n_sec = X_sec_test_full.shape[0]\n",
    "    n_cli = len(clin_severity_norm_clean)\n",
    "\n",
    "    # Random pairing indices\n",
    "    sec_idx = rng.integers(0, n_sec, size=n_pairs)\n",
    "    cli_idx = rng.integers(0, n_cli, size=n_pairs)\n",
    "\n",
    "    # Clean underlying scores and flags\n",
    "    sec_clean = sec_attack_score_clean[sec_idx]\n",
    "    sec_flag = sec_attack_flag[sec_idx]\n",
    "\n",
    "    clin_clean = clin_severity_norm_clean[cli_idx]\n",
    "    clin_flag = clin_flag_full[cli_idx]\n",
    "\n",
    "    # Ground-truth 3-class label from CLEAN flags\n",
    "    y = np.zeros_like(sec_flag, dtype=int)\n",
    "    y[(sec_flag == 1) & (clin_flag == 1)] = 2          # Critical\n",
    "    y[(sec_flag != clin_flag)] = 1                     # High (only one abnormal)\n",
    "\n",
    "    # Noisy observed scores\n",
    "    sec_obs = sec_clean + rng.normal(0.0, noise_std_sec, size=sec_clean.shape)\n",
    "    clin_obs = clin_clean + rng.normal(0.0, noise_std_clin, size=clin_clean.shape)\n",
    "\n",
    "    sec_obs = np.clip(sec_obs, 0.0, 1.0)\n",
    "    clin_obs = np.clip(clin_obs, 0.0, 1.0)\n",
    "\n",
    "    # Fused risk on noisy scores (what the model would use internally)\n",
    "    fused_risk_obs = np.array(\n",
    "        [_fusion_fun(s, c) for s, c in zip(sec_obs, clin_obs)],\n",
    "        dtype=float\n",
    "    )\n",
    "\n",
    "    # Final feature matrix\n",
    "    X = np.column_stack([sec_obs, clin_obs, fused_risk_obs])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# You can adjust these noise std values to reflect plausible measurement noise\n",
    "NOISE_STD_SEC = 0.05\n",
    "NOISE_STD_CLIN = 0.05\n",
    "\n",
    "N_PAIRS = 30000\n",
    "X_fusion, y_fusion = build_fusion_dataset_noisy(\n",
    "    n_pairs=N_PAIRS,\n",
    "    seed=2027,\n",
    "    noise_std_sec=NOISE_STD_SEC,\n",
    "    noise_std_clin=NOISE_STD_CLIN,\n",
    ")\n",
    "\n",
    "print(f\"\\n[INFO] Built noisy fusion dataset (features with noise, labels from clean flags):\")\n",
    "unique, counts = np.unique(y_fusion, return_counts=True)\n",
    "for v, c in zip(unique, counts):\n",
    "    label = {0: \"Stable\", 1: \"High\", 2: \"Critical\"}.get(int(v), str(v))\n",
    "    print(f\"  Class {v} ({label}): {c} samples\")\n",
    "\n",
    "# ---------------- Split into train / calibration / test ----------------\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X_fusion,\n",
    "    y_fusion,\n",
    "    test_size=0.40,\n",
    "    random_state=2027,\n",
    "    stratify=y_fusion,\n",
    ")\n",
    "\n",
    "X_calib, X_test, y_calib, y_test = train_test_split(\n",
    "    X_tmp,\n",
    "    y_tmp,\n",
    "    test_size=0.50,\n",
    "    random_state=2027,\n",
    "    stratify=y_tmp,\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] Fusion splits (stratified, noisy features):\")\n",
    "print(f\"  Train: {X_train.shape[0]} samples\")\n",
    "print(f\"  Calib: {X_calib.shape[0]} samples\")\n",
    "print(f\"  Test : {X_test.shape[0]} samples\")\n",
    "\n",
    "# ---------------- Base multinomial model (3 classes) ----------------\n",
    "base_clf = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=400,\n",
    ")\n",
    "\n",
    "base_clf.fit(X_train, y_train)\n",
    "\n",
    "# ---------------- Probability calibration on calib set ----------------\n",
    "calibrated_clf = CalibratedClassifierCV(\n",
    "    base_clf,\n",
    "    method=\"isotonic\",\n",
    "    cv=\"prefit\",\n",
    ")\n",
    "calibrated_clf.fit(X_calib, y_calib)\n",
    "\n",
    "# ---------------- Evaluation on test set ----------------\n",
    "probs_test = calibrated_clf.predict_proba(X_test)\n",
    "y_pred = np.argmax(probs_test, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    y_test, y_pred, labels=[0, 1, 2], zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n=== Probabilistic fusion model (noisy features) on TEST fusion set ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "for idx, name in zip([0, 1, 2], [\"Stable\", \"High\", \"Critical\"]):\n",
    "    print(\n",
    "        f\"{name:<8} | P={prec[idx]:.4f} | R={rec[idx]:.4f} | F1={f1[idx]:.4f} | support={support[idx]}\"\n",
    "    )\n",
    "\n",
    "macro_f1 = float(f1.mean())\n",
    "print(f\"\\nMacro-F1: {macro_f1:.4f}\\n\")\n",
    "\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        target_names=[\"Stable\", \"High\", \"Critical\"],\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# ---------------- Confusion matrix and figure export ----------------\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[\"Stable\", \"High\", \"Critical\"],\n",
    ")\n",
    "disp.plot(ax=ax, colorbar=False, cmap=\"Greys\")\n",
    "\n",
    "diag_colors = [\"green\", \"gold\", \"red\"]  # Stable, High, Critical\n",
    "for k, color in enumerate(diag_colors):\n",
    "    rect = Rectangle(\n",
    "        (k - 0.5, k - 0.5),\n",
    "        1,\n",
    "        1,\n",
    "        fill=True,\n",
    "        alpha=0.25,\n",
    "        edgecolor=color,\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(\"Probabilistic fusion (noisy features) – confusion matrix (TEST set)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "PROJECT_DIR = Path(\"/content/drive/MyDrive/Conference_paper_ICCC_2026\")\n",
    "OUTPUT_DIR = PROJECT_DIR / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig_path = OUTPUT_DIR / \"fusion_probabilistic_noisy_confusion_matrix.png\"\n",
    "fig.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"\\n[INFO] Probabilistic fusion confusion matrix (noisy features) saved to: {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2jpXh57uUzgB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590,
     "referenced_widgets": [
      "f5c928656eda4a7d87871d13bffe414e",
      "179ffff26aeb4eb59c5603152a0b6d4a",
      "43f140bad08449bc9f268c0184b181bd",
      "ff7ae1f8caa14075a2369b194437d436",
      "7aa61a97aa7c43f19615476ec3c05622",
      "d5eb1447a5dc4649b805c38c25660e4e",
      "f5e78f4d4dac4948902360f40be90d1b",
      "0361f713113748e58ca33202fb149a56",
      "314d3a2a802141e7a2074c76951dc91e",
      "7c52cd2c8a98427cb5bc303ce43154ec",
      "d24741b74eb447d0a5d34d168fac091f"
     ]
    },
    "id": "2jpXh57uUzgB",
    "outputId": "3703ed0c-b418-4a2b-be9d-41e4a081154c"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Export small DataFrames (tables) and matplotlib figures to Google Drive /output\n",
    "# Project root: /content/drive/MyDrive/Conference_paper_ICCC_2026\n",
    "# - Only DataFrames up to ~5 MB are exported (tables, not raw data)\n",
    "# - All matplotlib figures are exported as PNG (dpi=300)\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None  # Safety fallback\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "PROJECT_DIR = Path(\"/content/drive/MyDrive/Conference_paper_ICCC_2026\")\n",
    "OUTPUT_DIR = PROJECT_DIR / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_df = []\n",
    "log_fig = []\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Save only \"small\" pandas DataFrames as CSV (tables)\n",
    "# ------------------------------------------------------------------\n",
    "MAX_DF_BYTES = 5 * 1024 * 1024  # ≈ 5 MB in memory\n",
    "\n",
    "if pd is not None:\n",
    "    df_items = [\n",
    "        (name, obj)\n",
    "        for name, obj in list(globals().items())\n",
    "        if isinstance(obj, pd.DataFrame)\n",
    "    ]\n",
    "\n",
    "    if len(df_items) == 0:\n",
    "        print(\"No pandas DataFrames found in the current namespace.\")\n",
    "    else:\n",
    "        print(f\"Found {len(df_items)} DataFrames – exporting only small ones (≤ ~5 MB) to {OUTPUT_DIR} ...\")\n",
    "        for name, df in tqdm(df_items, desc=\"Saving small DataFrames\"):\n",
    "            approx_bytes = df.memory_usage(index=True, deep=True).sum()\n",
    "            if approx_bytes > MAX_DF_BYTES:\n",
    "                log_df.append(\n",
    "                    f\"[SKIP-LARGE] '{name}' not exported \"\n",
    "                    f\"(~{approx_bytes / (1024*1024):.1f} MB).\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            safe_name = re.sub(r\"[^0-9a-zA-Z_]+\", \"_\", name)\n",
    "            out_path = OUTPUT_DIR / f\"{safe_name}.csv\"\n",
    "            try:\n",
    "                df.to_csv(out_path, index=False)\n",
    "                log_df.append(f\"[OK] '{name}' -> {out_path.name}\")\n",
    "            except Exception as e:\n",
    "                log_df.append(f\"[ERROR] '{name}' not saved: {e}\")\n",
    "else:\n",
    "    print(\"pandas is not available; skipping DataFrame export.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Save all current matplotlib figures\n",
    "# ------------------------------------------------------------------\n",
    "fig_nums = plt.get_fignums()\n",
    "if len(fig_nums) == 0:\n",
    "    print(\"No open matplotlib figures to export.\")\n",
    "else:\n",
    "    print(f\"Found {len(fig_nums)} matplotlib figures – exporting to {OUTPUT_DIR} ...\")\n",
    "    for num in tqdm(fig_nums, desc=\"Saving figures\"):\n",
    "        fig = plt.figure(num)\n",
    "        out_path = OUTPUT_DIR / f\"figure_{num}.png\"\n",
    "        try:\n",
    "            fig.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "            log_fig.append(f\"[OK] Figure {num} -> {out_path.name}\")\n",
    "        except Exception as e:\n",
    "            log_fig.append(f\"[ERROR] Figure {num} not saved: {e}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Write a small manifest with a summary of what was exported\n",
    "# ------------------------------------------------------------------\n",
    "manifest_path = OUTPUT_DIR / \"export_manifest.txt\"\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    f.write(\"Export summary for this notebook run\\n\\n\")\n",
    "    f.write(\"=== DataFrames (tables) ===\\n\")\n",
    "    for line in log_df:\n",
    "        f.write(line + \"\\n\")\n",
    "    f.write(\"\\n=== Figures ===\\n\")\n",
    "    for line in log_fig:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ Export completed. Files saved under: {OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\n=== DataFrames export log (up to 20 entries) ===\")\n",
    "print(\"\\n\".join(log_df[:20]))\n",
    "if len(log_df) > 20:\n",
    "    print(f\"... ({len(log_df) - 20} more entries in export_manifest.txt)\")\n",
    "\n",
    "print(\"\\n=== Figures export log (all entries) ===\")\n",
    "print(\"\\n\".join(log_fig) if log_fig else \"(no figures found)\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0361f713113748e58ca33202fb149a56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "045d0c06345441bfac5d9e6d6da107a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "0a6082aaccf141e59200b9f272dd145e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "179ffff26aeb4eb59c5603152a0b6d4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5eb1447a5dc4649b805c38c25660e4e",
      "placeholder": "​",
      "style": "IPY_MODEL_f5e78f4d4dac4948902360f40be90d1b",
      "value": "Saving small DataFrames: 100%"
     }
    },
    "20a25de6f6c44b958cc847f61bedf97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "314d3a2a802141e7a2074c76951dc91e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "315b802f05ab4b818ba80f1779d9e5e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36e4a17d853d4b29823b2124cafc6134": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43f140bad08449bc9f268c0184b181bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0361f713113748e58ca33202fb149a56",
      "max": 22,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_314d3a2a802141e7a2074c76951dc91e",
      "value": 22
     }
    },
    "4ff337cd66d444fca99baa99f93f6254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c4542f0b3474a34b35f694760757778": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_936d9abda3f9422e803f1f669b380570",
       "IPY_MODEL_a920e47e90674200800b93617d1c8ce5",
       "IPY_MODEL_aca8b02bb4cd4285b257f695d87ff3cc"
      ],
      "layout": "IPY_MODEL_95f91f90396045c0a8a514a587e69b25"
     }
    },
    "795b65d7f23940b3a620c8a207e089f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7aa61a97aa7c43f19615476ec3c05622": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c52cd2c8a98427cb5bc303ce43154ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80b27a672ac44cf193e3eb4238eb29f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "884f46b4d6c54a0eb7d6870625fb3bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "899ad84ae73d4d5891a98d9a128db75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b117d72294f7417bb9762a278107fca5",
       "IPY_MODEL_cd4bc3d9a3c04b6dbad129e7bd22d970",
       "IPY_MODEL_bf35cdafc4a34443ba20b54d0ab06716"
      ],
      "layout": "IPY_MODEL_045d0c06345441bfac5d9e6d6da107a3"
     }
    },
    "936d9abda3f9422e803f1f669b380570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab893a82edeb4216b77959f5501e7726",
      "placeholder": "​",
      "style": "IPY_MODEL_315b802f05ab4b818ba80f1779d9e5e3",
      "value": "FAST pass (interval=60min) x8: 100%"
     }
    },
    "95f91f90396045c0a8a514a587e69b25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a920e47e90674200800b93617d1c8ce5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ff337cd66d444fca99baa99f93f6254",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36e4a17d853d4b29823b2124cafc6134",
      "value": 1000
     }
    },
    "ab893a82edeb4216b77959f5501e7726": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aca8b02bb4cd4285b257f695d87ff3cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80b27a672ac44cf193e3eb4238eb29f1",
      "placeholder": "​",
      "style": "IPY_MODEL_b37db04d276c46b1a3ef9ea3cc28b245",
      "value": " 1000/1000 [1:01:32&lt;00:00,  3.36s/it]"
     }
    },
    "b117d72294f7417bb9762a278107fca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_795b65d7f23940b3a620c8a207e089f7",
      "placeholder": "​",
      "style": "IPY_MODEL_884f46b4d6c54a0eb7d6870625fb3bf4",
      "value": "AE inference:   0%"
     }
    },
    "b37db04d276c46b1a3ef9ea3cc28b245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf35cdafc4a34443ba20b54d0ab06716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7aee10c731647fd9d02944670c67fc8",
      "placeholder": "​",
      "style": "IPY_MODEL_e7e8e44731c1403c8683ee6d2e08821b",
      "value": " 0/1 [00:00&lt;?, ?it/s]"
     }
    },
    "c7aee10c731647fd9d02944670c67fc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd4bc3d9a3c04b6dbad129e7bd22d970": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a6082aaccf141e59200b9f272dd145e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20a25de6f6c44b958cc847f61bedf97e",
      "value": 1
     }
    },
    "d24741b74eb447d0a5d34d168fac091f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5eb1447a5dc4649b805c38c25660e4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7e8e44731c1403c8683ee6d2e08821b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5c928656eda4a7d87871d13bffe414e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_179ffff26aeb4eb59c5603152a0b6d4a",
       "IPY_MODEL_43f140bad08449bc9f268c0184b181bd",
       "IPY_MODEL_ff7ae1f8caa14075a2369b194437d436"
      ],
      "layout": "IPY_MODEL_7aa61a97aa7c43f19615476ec3c05622"
     }
    },
    "f5e78f4d4dac4948902360f40be90d1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff7ae1f8caa14075a2369b194437d436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c52cd2c8a98427cb5bc303ce43154ec",
      "placeholder": "​",
      "style": "IPY_MODEL_d24741b74eb447d0a5d34d168fac091f",
      "value": " 22/22 [00:03&lt;00:00,  4.12it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
